---
layout: post
title:  "Docker 开始，第 3 部分：服务"
date:   2017-02-14
excerpt: "Get Started, Part 3: Services"
tags: [Docker]
comments: true
---
 前提
 - 安装 Docker 1.13 版本或更高。
 - 获取 Docker Compose。在 Docker for Mac 和 Docker for Windows 上，它是预先安装好的，所以你很好的选择。在 Linux 系统上，您需要直接安装它。在没有 Hyper-V 的 Windows 10 之前系统上，使用 Docker Toolbox。
 - 阅读第 1 部分的目标。
 - 在第 2 部分中了解如何创建容器。
 - 确保您已经通过推送到注册表方式发布了您创建的`friendlyhello`镜像。我们在这里使用该共享的镜像。
 - 确保您的镜像可像已部署的容器一样工作。运行此命令，将您的信息中插入`username`、`repo`和`tag`中：`docker run -p 80:80 username/repo:tag`，然后访问`http://localhost/`。 
 
> ## Introduction 
 
> In part 3, we scale our application and enable load-balancing. To do this, we must go one level up in the hierarchy of a distributed application: the service . 
> - Stack 
> - Services (you are here)
> - Container (covered in part 2 )
 
 介绍 
 
 在第3部分中，我们扩展我们的应用程序并启用负载平衡。要做到这一点，我们必须在分布式应用程序的层次结构中上升一个级别：服务。 
 - 堆栈
 - 服务（这里）
 - 容器
 
 About services 
 
 关于服务 
 
 In a distributed application, different pieces of the app are called “services.” For example, if you imagine a video sharing site, it probably includes a service for storing application data in a database, a service for video transcoding in the background after a user uploads something, a service for the front-end, and so on. 
 
 在分布式应用程序中，应用程序的不同部分被称为“服务”。例如，如果您想象一个视频共享站点，它可能包括一个用于将应用程序数据存储在数据库中的服务，一个用于在用户上传某些内容后在后台进行视频转换的服务，以及一个用于前端的服务，等等。 
 
 Services are really just “containers in production.” A service only runs one image, but it codifies the way that image runs—what ports it should use, how many replicas of the container should run so the service has the capacity it needs, and so on. Scaling a service changes the number of container instances running that piece of software, assigning more computing resources to the service in the process. 
 
 服务实际上只是“生产中的容器”。服务只运行一个映像，但它编码了映像的运行方式--应该使用哪些端口，应该运行多少个容器副本，以便服务具有所需的容量，等等。扩展服务会改变运行该软件的容器实例的数量，为流程中的服务分配更多的计算资源。 
 
 Luckily it’s very easy to define, run, and scale services with the Docker platform – just write a docker-compose.yml file. 
 
 幸运的是，它的定义，很容易，并与码头平台–规模服务只写一个docker-compose.yml文件。<br/> 
 
 Your first docker-compose.yml file 
 
 你的第一docker-compose.yml文件<br/> 
 
 A docker-compose.yml file is a YAML file that defines how Docker containers should behave in production. 
 
 yml文件是一个YAML文件，它定义了Docker容器在生产中的行为方式。 
 
 docker-compose.yml 
 
 Docker-Compose.yml 
 
 Save this file as docker-compose.yml wherever you want. Be sure you have pushed the image you created in Part 2 to a registry, and update this .yml by replacing username/repo:tag with your image details. 
 
 将此文件保存为docker-compose.yml。确保您已经将在第2部分中创建的映像推送到注册表中，并通过用图像详细信息替换username/repo：tag来更新这个.yml。 
 
 version : " 3" services : web : # replace username/repo:tag with your name and image details image : username/repo:tag deploy : replicas : 5 resources : limits : cpus : " 0.1" memory : 50M restart_policy : condition : on-failure ports : - " 80:80" networks : - webnet networks : webnet : 
 
 版本：“3”服务：web：#替换用户名/repo：标记为您的名称和图像详细信息图像：username/repo：标记部署：复制：5个资源：限制：cpu：“0.1”内存：50m重新启动_policy：条件：启动失败端口：-“80：80”网络：-webnet网络：webnet：webnet：webnet： 
 
 This docker-compose.yml file tells Docker to do the following: 
 
 这docker-compose.yml文件告诉工人要做到以下几点：<br/> 
 
 Pull the image we uploaded in step 2 from the registry. Run 5 instances of that image as a service called web , limiting each one to use, at most, 10% of the CPU (across all cores), and 50MB of RAM. Immediately restart containers if one fails. Map port 80 on the host to web ’s port 80. Instruct web ’s containers to share port 80 via a load-balanced network called webnet . (Internally, the containers themselves publish to web ’s port 80 at an ephemeral port.) Define the webnet network with the default settings (which is a load-balanced overlay network). 
 
 从注册表中提取我们在步骤2中上传的图像。作为一个名为Web的服务运行该映像的5个实例，限制每个实例最多使用10%的cpu(跨所有核)和50 MB的RAM。如果容器失败，立即重新启动容器。将主机上的端口80映射到web的端口80。指示web的容器通过一个称为webnet的负载均衡网络共享端口80。(在内部，容器本身在一个临时端口发布到web的端口80。)。使用默认设置(这是一个负载平衡的覆盖网络)定义webnet网络。 
 
 Run your new load-balanced app 
 
 运行您的新负载平衡应用程序。 
 
 Before we can use the docker stack deploy command we first run: 
 
 在使用docker堆栈部署命令之前，首先运行： 
 
 docker swarm init 
 
 码头群 
 
 Note : We get into the meaning of that command in part 4 . If you don’t run docker swarm init you get an error that “this node is not a swarm manager.” 
 
 注意：我们在第4部分中理解了该命令的含义。如果您没有在其中运行停靠群，则会出现一个错误，即“此节点不是群集管理器”。 
 
 Now let’s run it. You need to give your app a name. Here, it is set to getstartedlab : 
 
 现在让我们运行它。你需要给你的应用程序一个名字。在这里，它被设置为getstartedlab： 
 
 docker stack deploy -c docker-compose.yml getstartedlab 
 
 Docker堆栈部署-c docker-Compose.yml getstartedlab 
 
 Our single service stack is running 5 container instances of our deployed image on one host. Let’s investigate. 
 
 我们的单个服务堆栈正在一个主机上运行我们部署的映像的5个容器实例。让我们调查一下。 
 
 Get the service ID for the one service in our application: 
 
 获取应用程序中的一个服务的服务ID： 
 
 docker service ls 
 
 码头服务 
 
 Look for output for the web service, prepended with your app name. If you named it the same as shown in this example, the name is getstartedlab_web . The service ID is listed as well, along with the number of replicas, image name, and exposed ports. 
 
 查找Web服务的输出，并加上您的应用程序名。如果您将它命名为与本例相同的名称，则名称为getstartedlab_web。还列出了服务ID，以及副本、图像名和公开端口的数量。 
 
 A single container running in a service is called a task . Tasks are given unique IDs that numerically increment, up to the number of replicas you defined in docker-compose.yml . List the tasks for your service: 
 
 在服务中运行的单个容器称为任务。任务被赋予唯一的ID，在数字上增加，直到在docker-Compose.yml中定义的副本的数量。列出服务的任务： 
 
 docker service ps getstartedlab_web 
 
 Docker服务ps getstartedlab_web 
 
 Tasks also show up if you just list all the containers on your system, though that is not filtered by service: 
 
 如果您只列出系统上的所有容器，那么任务也会显示出来，尽管服务没有过滤这些容器： 
 
 docker container ls -q 
 
 码头货柜ls-q 
 
 You can run curl -4 http://localhost several times in a row, or go to that URL in your browser and hit refresh a few times. 
 
 您可以连续运行curl-4http：//localhost几次，也可以在浏览器中转到该URL，并按几次刷新。 
 
 Either way, the container ID changes, demonstrating the load-balancing; with each request, one of the 5 tasks is chosen, in a round-robin fashion, to respond. The container IDs match your output from the previous command ( docker container ls -q ). 
 
 无论哪种方式，容器ID都会改变，演示负载平衡；对于每个请求，将以循环方式选择其中一个任务来响应。容器ID与前面命令(docker容器ls-q)的输出相匹配。 
 
 Running Windows 10? Windows 10 PowerShell should already have curl available, but if not you can grab a Linux terminal emulator like Git BASH , or download wget for Windows which is very similar. 
 
 运行Windows 10？Windows 10 PowerShell应该已经有了curl，但是如果没有，您可以抓取一个Linux终端仿真器，比如Git Bash，或者下载非常类似的wget for Windows。 
 
 Slow response times? Depending on your environment’s networking configuration, it may take up to 30 seconds for the containers to respond to HTTP requests. This is not indicative of Docker or swarm performance, but rather an unmet Redis dependency that we address later in the tutorial. For now, the visitor counter isn’t working for the same reason; we haven’t yet added a service to persist data. 
 
 反应缓慢？根据您环境的网络配置，容器响应HTTP请求可能需要30秒的时间。这并不表示Docker或S批的性能，而是一个未满足的Redis依赖关系，我们将在本教程的后面讨论。目前，访问者计数器的工作原因并不相同；我们还没有添加一个服务来持久化数据。 
 
 Scale the app 
 
 缩放应用程序 
 
 You can scale the app by changing the replicas value in docker-compose.yml , saving the change, and re-running the docker stack deploy command: 
 
 您可以通过更改docker-Compose.yml中的副本值、保存更改并重新运行docker堆栈部署命令来扩展应用程序： 
 
 docker stack deploy -c docker-compose.yml getstartedlab 
 
 Docker堆栈部署-c docker-Compose.yml getstartedlab 
 
 Docker performs an in-place update, no need to tear the stack down first or kill any containers. 
 
 Docker执行就地更新，不需要首先拆下堆栈或杀死任何容器。 
 
 Now, re-run docker container ls -q to see the deployed instances reconfigured. If you scaled up the replicas, more tasks, and hence, more containers, are started. 
 
 现在，重新运行docker容器ls-q，以查看已部署的实例重新配置。如果您扩展副本，那么会启动更多的任务，从而启动更多的容器。 
 
 Take down the app and the swarm 
 
 把应用程序和蜂群取下来 
 
 Take the app down with docker stack rm : docker stack rm getstartedlab Take down the swarm. docker swarm leave --force 
 
 把应用程序与码头堆栈rm：码头堆叠rm的启动实验室，拿下蜂群码头群离开-力量 
 
 It’s as easy as that to stand up and scale your app with Docker. You’ve taken a huge step towards learning how to run containers in production. Up next, you learn how to run this app as a bonafide swarm on a cluster of Docker machines. 
 
 站起来和用Docker扩展你的应用程序一样容易。您已经在学习如何在生产中运行容器方面迈出了一大步。接下来，您将了解如何在一组Docker机器上运行这个应用程序。 
 
 Note : Compose files like this are used to define applications with Docker, and can be uploaded to cloud providers using Docker Cloud , or on any hardware or cloud provider you choose with Docker Enterprise Edition . 
 
 注意：像这样的组合文件用于用Docker定义应用程序，并且可以使用DockerCloud上传到云提供商，或者在DockerEnterpriseEdition中选择的任何硬件或云提供者上。 
 
 On to “Part 4” » 
 
 关于“第四部分” 
 
 Recap and cheat sheet (optional) 
 
 重述和备忘单(可选) 
 
 Here’s a terminal recording of what was covered on this page : 
 
 以下是本页所涵盖内容的终端记录： 
 
 To recap, while typing docker run is simple enough, the true implementation of a container in production is running it as a service. Services codify a container’s behavior in a Compose file, and this file can be used to scale, limit, and redeploy our app. Changes to the service can be applied in place, as it runs, using the same command that launched the service: docker stack deploy . 
 
 总之，输入docker运行非常简单，但生产中容器的真正实现是将其作为服务运行。服务将容器的行为编码在一个组合文件中，这个文件可以用于扩展、限制和重新部署我们的应用程序。在服务运行时，可以使用启动服务的相同命令：Docker堆栈部署，将对服务的更改应用到相应的位置。 
 
 Some commands to explore at this stage: 
 
 在此阶段需要研究的一些命令： 
 
 docker stack ls # List stacks or apps docker stack deploy -c <composefile> <appname> # Run the specified Compose file docker service ls # List running services associated with an app docker service ps <service> # List tasks associated with an app docker inspect <task or container> # Inspect task or container docker container ls -q # List container IDs docker stack rm <appname> # Tear down an application docker swarm leave --force # Take down a single node swarm from the manager 
 
 Docker堆栈ls#list堆栈或应用程序停靠堆栈部署-c<Composefile><appname>>#运行指定的复合文件停靠服务ls#list运行与应用程序停靠服务ps<service>#list任务关联的应用程序停靠服务ps<service>#list任务与应用程序停靠者检查<任务或容器>#test任务或容器容器ls-q#list容器ID rm<appname>拆下应用程序停靠器。群离开-强制#从经理处取下一个节点群。 
 
 services , replicas , scale , ports , compose , compose file , stack , networking 
 
 服务，副本，缩放，端口，合成，合成文件，堆栈，网络 
 
 PDRTJS_settings_8453675 = { 										"id": "8453675", 										"unique_id": "get-started/part3.md", 										"title": "Get Started, Part 3: Services", 										"permalink": "https://github.com/docker/docker.github.io/blob/master/get-started/part3.md" 									}; 									(function(d, c, j) { 										if (!document.getElementById(j)) { 											var pd = d.createElement(c), 												s; 											pd.id = j; 											pd.src = ('https:' == document.location.protocol) ? 'https://polldaddy.com/js/rating/rating.js' : 'http://i0.poll.fm/js/rating/rating.js'; 											s = document.getElementsByTagName(c)[0]; 											s.parentNode.insertBefore(pd, s); 										} 									}(document, 'script', 'pd-rating-js')); 
 
 ... 
 
 
 
 

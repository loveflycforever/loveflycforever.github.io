从意识上要重视数据采集工作。数据的事情归结起来就两点：数据采集和数据分析。

数据分析的基础就是数据源，数据源一般分为两部分：一部分叫用户行为数据，主要在APP的前后端埋点；另一部分，叫业务数据，一般存储在后台数据库。



## 数据分析结论
APP的产品经理，通过分析笔者这类用户的行为数据，得出了以下结论：

用户查看排行榜后，80%选择对排行第一的产品进行下单购买，15%选择购买排名第二的产品，其它5%没有发生购买。（行为数据分析）。
笔者在后台被打上了高级用户标签，这种用户人数占活跃用户数的30%，但贡献了60%的交易额，同时这个标签群体的退货率不到2%。（业务数据分析）。
84%的用户在商品列表页翻页时，最多翻到4页就选择跳出，而最多翻页的用户，剔除极端异常数据后，一般是翻到10页左右。通常搜索结果在10页以上且发生购买的情况下，前五页商品被下单的概率高达88%。（行为数据、业务数据结合分析）。


# 清晰的数据埋点

产品可能产生的用户行为数据纷繁复杂，清晰的目标能让项目团队避免迷失在数据的海洋中，从而耗费大量的时间和机会成本。

数据埋点的前提是，团队需要首先明确目前产品最亟待解决的问题是什么。

举个例子，比如电商产品，那么可能最首要的问题就是交易额，如何突破交易额，分解下去，可能就涉及到流量、转化率、客单价、回购率等等，提升这些数据指标就是当前产品的首要问题。
在整个产品的分析和改进过程中，需要持续的观察这些指标的变化。


在分析的一开始，并不建议采集太多的用户行为，在这一点上，倒是很像做产品里面的MVP（最小可化产品）思路，敏捷地不断迭代，不要一下子把全部用户行为都采集齐全。
因为如果产品经理在一开始就试图设计实施一套庞大、全面的方案，很容易陷入复杂而又细节的泥潭并导致失败，即便最终成功，也极可能会（因为初期的错误规划）导致很多时间浪费。
在一开始只记录和分析与“产品目标”最为相关的少量用户行为（如浏览、购买、下单），这样很快就能有成果产出。

# 数据采集

数据采集的问题归结为三类：

不知道怎么采，包括采集什么数据以及用什么技术手段采集；
埋点混乱，出现埋错、漏埋这样的问题；
数据团队和业务工程团队配合困难，往往产品升级的优先级大于数据采集的优先级。


## 先提问后解决

不知道埋点的全生命周期是怎样的，只有片段概念？
如何将业务需求转换为数据需求？
埋点文档怎么写？事件、参数是什么？
埋点管理如何进行，管理平台如何搭建？
埋点数据如何进行可视化展现？
埋点数据准确性如何保障？


### 埋点的生命周期主要分为以下三个阶段：

（1）需求阶段：进行需求采集和需求分析，保证埋点满足核心业务需求

数据需求池：对数据需求进行整体维护，记录需求业务场景、需求内容、提出者、时间等
产品信息架构：梳理产品结构，熟悉产品
用户行为路径：分析用户路径，得到核心业务指标

（2）设计阶段：进行埋点版本规划和埋点设计

埋点版本规划：根据需求优先级，分版本上线，快速迭代；
埋点文档：详细描写版本记录、数据流程图、埋点事件等内容；
后台原型设计：埋点管理后台、数据可视化平台原型。

（3）质量管理阶段：保障埋点数据的准确及有效

数据准确性验证：埋点数据的准确性需要及时得到验证，以保证后续数据质量；
数据监控：定期监控埋点数据的产生情况；
埋点下线：没有价值、不符合当前需求的埋点进行下线。



http://image.woshipm.com/wp-files/2020/02/AQmD6Ci1CYCiPtjYSGYA.jpeg


## 如何采集数据

### 第三方

第一种直接使用友盟、百度统计这样的第三方统计工具，嵌入 App SDK 或 JS SDK，来直接查看统计数据。这种方式的好处是简单、免费，因此使用非常普及。

对于看一些网站访问量、活跃用户量这样的宏观数据需求，基本能够满足。对于现在一些涉及订单交易类型的产品，仅仅宏观的简单统计数据已经不能满足用户的需求了。

更加关注一些深度的关键指标分析，例如：用户渠道转化、新增、留存、多维度交叉分析等。这个时候才发现第三方统计工具很难满足对数据的需求，而出现这样的问题并不是因为工具的分析能力薄弱，而是因为这类工具对于数据采集的不完整。

通过这种方式 SDK 只能够采集到一些基本的用户行为数据，比如设备的基本信息，用户执行的基本操作等。但是服务端和数据库中的数据并没有采集，一些提交操作，比如提交订单对应的成本价格、折扣情况等信息也没有采集，这就导致后续的分析成了“巧妇难为无米之炊”。

通过客户端 SDK 采集数据还有一个问题就是经常觉得统计不准，和自己的业务数据库数据对不上，出现丢数据的情况。这是前端数据采集的先天缺陷，因为网络异常，或者统计口径不一致，都会导致数据对不上。

### 业务数据库
第二种是直接使用业务数据库做统计分析，一般的互联网产品，后端都有自己的业务数据库，里面存储了订单、用户注册信息等数据，基于这些数据，一些常用的统计分析都能够搞定。

这种方式天然的就能分析业务数据，并且是实时、准确的。

但不足之处有两点：

一是业务数据库在设计之初就是为了满足正常的业务运转，给机器读写访问的。为了提升性能，会进行一些分表等操作。
一个正常的业务都要有几十张甚至上百张数据表，这些表之间有复杂的依赖关系。这就导致业务分析人员很难理解表含义。
即使硬着头皮花了两三个月时间搞懂了，隔天工程师又告诉你因为性能问题拆表了，你就崩溃了。

另一个不足之处是业务数据表的设计是针对高并发低延迟的小操作，而数据分析常常是针对大数据进行批量操作的，这样就导致性能很差。

### 基于日志

第三种是通过日志进行统计分析，这种方式相较于第二种，完成了数据的解耦，使业务数据和统计分析数据相互分离。
然而，这种方式的问题是“目的不纯”。日志往往是工程师为了方便 Debug 顺便搞搞，这样的日志对于业务层面的分析，常常“缺斤少两”。
并且从打印日志到处理日志再到输出结果，整个过程很容易出错。

只能采集前端数据，后端服务器和数据库中的数据，依旧是无可奈何的。
并且，即便进行前端数据采集，也无法深入到更细粒度。比如提交订单操作，订单运费、成本价格之类的维度信息，都丢失掉了，只剩下“提交”这一个行为类型。


## 基本原则

数据采集的基本原则是全和细。
全就是把多种数据源都进行采集，而不只是客户端的用户数据。
细就是强调多维度，把事件发生的一系列维度信息，比如订单运费、成本价格等，尽量多的记录下来，方便后续交叉分析。


对数据采集工作负责，每次数据采集点的增加或变更，都要经过系统化的审核管理，不能顺便搞搞。

最后，我这里要推荐 Event 数据模型，针对用户行为数据，简化成一张宽表，将用户的操作归结为一系列的事件。



## 埋点设计原则


坚守五个原则：

需求清晰。
合理设计。
实施规范。
结果可验。
规范管理。



2.1 唯一原则
埋点字段相互独立，能精确定位某个事件或行为；即能通过1~2个参数精确定位到某个行为事件，例如在搜索页面“确认搜索”按钮的点击事件为search，那就要避免同页面内有其他事件被命名为search；

2.2 枚举原则
将所有可能需要的数据涉及的埋点一一枚举，可以根据页面穷举，也可以根据流程穷举，保证不出现漏埋的情况；

2.3 精确描述
每个埋点事件的做到无争议的描述，包括但不限于：采集逻辑，数据结构，特殊情况处理等；

普通的点击事件采集逻辑大概率不有理解上的偏差，大多数发生在以下情况

涉及发生后的状态上报：例如微信分享，是需要点击分享按钮即上报，还是点击跳转成功后上报？
涉及曝光埋点：例如内容曝光，用户上下滑动是否需要重复曝光？切换导航是否需要重新曝光？从详情页返回是否已曝光内容是否需要再次曝光？
涉及内容展示楼层埋点：例如内容流从上到下floor记为1,2,3…，不同类型是否共用楼层计数（例如文章123，第四位出现广告位是要上报4还是重新计数1）
数据结构就如字面意思，定义上报字段的数据类型，整型/字符串等等，这方面不是很熟悉最好BI或者分析师确认，以便后续处理数据；

特殊的情况例如，一次上报内容较多，需要定义格式，类似一组搜索联想词曝光，我们就需要定义“’联想词1’，’联想词2’，…”的json格式上报；
预先定义数据结构还有一个好处，就是能保持ios，Android两端上报一致，有利于提高后期的数据清洗及处理的效率；




1. 准确性原则
埋点事件一定是有效事件，而不是单纯的事件频次，下面是两个说明案例：

案例1

产品逻辑：点击某个按钮，会进入到某个指定的页面。

统计目标：计算『点击按钮』→『页面展示』的事件频次转化率。

计算公式：转化率 = 页面展示次数÷按钮点击次数

埋点说明：如果仅仅把页面展示的次数作为分子，会导致整个漏斗统计出错。除了存在多个途径进入该页面的可能，还一个重要的原因：从该页面进入其他页面，并且从其它页面返回至该页面的时候，该页面的展示也会被统计一次，如此计算的转化率比真实情况要高。在该案例中，应该定义『有效页面pv』：只有按钮点击进入该页面，才算做一次有效的『页面展示』事件。

案例2

产品逻辑：某个弹窗弹出，弹窗上有『确定』和『取消』两个按钮。

统计目标：计算『弹窗弹出』→『确定按钮点击』的频次转化率。

计算公式：转化率=确定按钮的点击次数÷弹窗的弹出次数

埋点说明：其中，『确定按钮点击』应该是有效点击，因为在无网或者卡顿情况下，存在用户需点击多次按钮，弹窗才能消失的情况。这种情况下，第二步的事件数是大于第一步的。在进行类似埋点的时候，应该定义第二步的有效点击：只要用户点击了按钮，不管点了多少次，只算一次。

2. 高类聚，低耦合原则
如果是产品模块之间的漏斗统计，建议为每个单独的模块设置一个事件作为代表，而不是使用模块内部所包含的所有事件。

从产品结构上来说，模块与模块之间比较独立，但是模块内部往往由复杂的逻辑组成，所以将这些复杂的逻辑抽象成一个独立的有效事件，有助于理清每个模块间的转化关系。

案例

产品逻辑：为了增加产品的使用时长，所以增加了积分体系逻辑，用户可以在产品不同的地方，看到各种任务引导，然后通过完成不同的任务，兑换相应的积分，领取对应的奖励。

统计目标：计算『任务引导』→『任务完成』的转化率

计算公式：转化率 = 任务完成次数÷任务引导次数

埋点说明：在积分体系中，应该将任务引导和完成任务分别抽象为两个单独的事件：只要任务引导出现，不管是哪种类型，哪个位置的引导，统统算作是『任务引导事件』。同理，不管用户完成了哪个任务，也应该统统算作为『任务完成事件』。如此一来，能够很轻松地从整体评估任务从曝光到完成的转化率。若是对每个任务的曝光事件与完成都进行埋点分析，则是一个十分复杂繁琐的过程。

3. 结果归一性原则
如果某个动作的发生，必然导致另外一个唯一结果事件，则建议只统计结果事件即可，对于很多统计平台来说，事件是十分稀有的资源。例如，Firebase最多允许添加500个事件，超出事件便不再显示。

当这两个事件具有高度的重合性与替代性，显然结果事件对于数据分析更具有价值。

案例

产品逻辑：内购宣传页面有多个曝光入口，可以通过点击首页的卡片进入，也可以通过点击弹窗进入。

统计目标：统计内购宣传页的展示次数。

埋点说明：为了获得统计目标，只需要记录内购宣传页的展示事件即可，而主页卡片的点击事件与弹窗点击事件可以由『内购宣传页』的键值对来表示。如此一来，既能分析出内购宣传页面的展示与入口分布，又能节约了两个入口事件。



4. 有效性原则
这一点是对上一点的补充，每个事件都应该对产品有着实际的分析价值与指导意义。对于那些没有指导意义的事件，请勿添加。

这点对于刚接触埋点设计的同学尤为重要，因为刚接触埋点的时候，可能会存在『宁可错埋一千，也不放过一个』的想法，这往往会浪费大量的事件资源。

对于产品逻辑不相关的事件不要添加，例如：弹窗关闭按钮的点击事件；
对于产品改善没有任何指导意义的事件不要添加，例如：固定动画的播放事件。
5. 分散与统一原则
如果一个事件，需要从多个维度进行分析，不仅每个维度在逻辑上相互关联，而且要求统计上又相互独立，则可以针对每个维度进行独立的统计。同时，也建议把这些维度连接起来，作为一个整体的维度进行分析。

案例1

产品逻辑：一个购物商城包含多类商品（电子产品、日化产品等），每类商品有包含多种具体的产品。例如电子产品包含XX型号手机、XX型号电脑……用户可以通过选择某个商品，并点击付款按钮，完成付款行为。

统计目标：计算每类商品所在的销售额与利润

计算公式：

电子产品总销售额=所有用户购买的电子产品销售额累加值
电子产品总利润=所有用户购买的电子产品利润累加值
日化产品总销售额……
埋点说明：每个商品都有专属的种类、售价与利润，其中种类、售价与利润三个维度相互独立，如果将这三个维度作为独立的三个键值对，如下表所示：



会对统计目标造成割裂，上面的埋点要么只能统计商品种类数目，要么只能统计总销售额，要么只能统计总利润，无法实现统计目标。

所以，推荐将这三个维度连接起来作为一个键，如下表所示：



这样可以通过SQL语句获取用户使用的原始数据，然后通过简单地数据处理，就能得出用户准确的使用情况。

这里的连接符推荐使用^，而不是_，因为很多命名的默认分隔符_，所以如果再以_作为分隔符，可能会给后续的数据处理造成麻烦。


## 怎么做

很多产品经理会将“用户行为”简单的等同于应用的页面（界面）或点击操作，其实这完全是两件事情。

用户行为是更加具体的一个事件定义，比如说用户“提交订单”这么一个行为，就可以定义为一个事件了，但是如果用页面点击去定义它，则过于抽象不具体，不能让其他人很直观地感受到这个事件定义出来到底是干嘛的。


第一步把所有的用户访问分为N个会话（我们会话的间隔时间定义为20分钟，也就是访问一个页面后如果超过20分钟才访问下一个页面，那下一个页面就算另外一个会话）。

第二步找出用户首次访问包含这些入口的会话。

第三步把用户的访问路径打横，遍历用户的访问路径如果满足我们定义的路径，这条路径就会算一个UV。计算时商品列表页它是从搜索来的，还是从分类来的，还是直接从首页来的已经提前打好标识。


在这个时候可以从以下几个方面来考虑：

产品目标可以通过哪几个重要指标衡量？
和指标最相关的用户的“关键行为”是什么？
用户在做「关键行为」之前和之后，还有哪些行为值得关注和分析？

![Image text](http://image.woshipm.com/wp-files/2017/03/AQl6wjeFwGRT3IT9onez.png)

根据上面梳理的用户行为流程及事件，我们可以尝试着梳理一下埋点事件表，如下图所示：

![Image text](http://image.woshipm.com/wp-files/2017/03/61b6Ivzc0auD0fHZEIXJ.png)

数据分析不能单纯的靠一些基本事件来进行，还涉及的事件属性会比较多，所以产品经理也可以在事件埋点表中补充关于事件属性这么一项。
为事件增加属性，是一种更细致的、更精确的记录和刻画用户行为的方式。
比如，某个用户打开了一个吹风机的商品详情页，可以详细描述如下： 事件：查看商品详情-商品类目：家用电器 -价格区间：100-399 -商品名称： 飞科吹风机 某某某型号…

![Image text](http://image.woshipm.com/wp-files/2017/03/wo12nw9aK2kBgBwU6yp1.png)



根据产品流程设计指标
在前面做了一系列的功课之后，我们就开始要根据产品的功能流程或者页面结构，定义好分析的目的，剥离关键流程，提炼关键指标。

购物环节：宝贝详情页>加入购物车>订单确定>订单提交>支付>支付结果

在这个过程中，你可能需要采集到从详情页到购物车的转化，从详情页到订单确认的转化，订单从确认到支付成功之间的漏斗模型。

那么对应的可以为详情页UV、购物车添加事件、订单确认事件、订单提交事件、支付事件、支付成功反馈事件。

注册流程：进入注册>注册信息填写>获取验证>注册成功

对应的可能想要了解到注册流程的转化，那么可以主要采集注册按钮点击事件、提交信息事件、获取验证事件、注册成功事件，再加上能够统计到渠道包信息，那么也就可以分析出，不同渠道下的用户转化效果。

### 坑点

第一坑：遗漏

指的是埋点采集不全面，有可能重要的数据并没有采集到，会对数据分析造成比较直接的影响，出现这个问题的原因是前期数据分析需求不清晰。

第二坑：杂乱

指的是数据采集比较零散，可以理解为前期并没有进行事件结构化的设计，通常是想到一个需求，就把这个需求提供给技术进行埋点。

这种称之为“扁平化”的埋点方式，例如：某一个位置或者某一个功能的点击行为，就当做一个事件进行采集，看上去采集和查看很容易，但随着时间跟需求的增加，当采集了大量零散的事件之后，需要在统计工具中通过分组分析时，就会比较麻烦。

第三坑：低效

不同于杂乱，杂乱是任何行为数据都会直接当事件去进行采集，没有利用参数去进行结构化的设计。低效指的是在事件设计的时候，会去做结构化处理。但事件设计的参数逻辑会有问题，通常都是以大的页面这种框架的思维去进行设计。

举个例子：部分客户在设计时，会按照页面的思路去进行事件采集，页面上有推荐位，还有很多功能按钮的点击，那么就会把这个页面所有的点击行为都归到一个事件，并且点击具体的按钮和内容都当做参数传回来。

但这里埋着两个雷区：

在分析数据时，例如想了解整个用户浏览内容的情况，或者是想了解某个功能（搜索引擎）整体使用情况，按照如上设计，内容和功能的采集都分布在每一个事件中了，这样后面再归类、分析就非常不方便。
当产品结构产生变化时，原有事件调整概率会比较大，因为之前都是按页面结构去设计，页面的调整直接影响事件采集。
第四坑：无用

指的是数据虽然采集了，但分析时根本用不上，这个问题主要有2个原因导致：一是前期需求不太清晰，另一个是之前的采集需求都是由不同人提出的。由于中间人员变动，很多采集需求就不清楚了，并且也不敢下掉，因为并不清楚这个事件是否还有人使用。

第五坑：复用

指的是事件重复采集，或者是需求重复，这个同样是与多个人提需求有关，并没有一个人去做整合管理，或者是说，没有一个工具去帮忙我们做管理。

### 通用字段

上报/采集时间
来源业务线
来源终端 APP/微信/官网
来源渠道
经纬度，等等。
这个业务侧可以根据业务需求增加多个，个性化很强的上报，放在同一个json格式的字段即可。


字段注意点和应用场景：

item_id：内容id，易错传为序列id
type：内容类型，如图文、视频、音频，可区分内容类型作分析
referer_id：上一页面内容id，可用于相关推荐业务的分析
_pt/_pi/_pm系列：定位页面和模块，可用于不同业务线的分析，例如首页、要问频道、正文页等
_pre_系列：追踪了上一级页面，可用于用户行为路径分析
除了关注字段的定义和场景外，还需留意上报时机，定义尽可能周全，就以此视频浏览事件为例：

页面退出（销毁）时：点击返回等
切换到其他视频：点击上下集，点击相关视频等
按home键退出时
锁屏时
app杀死时

以刷新事件（_fsE）为例：

direction：可供产品汪区分上拉、下拉作刷新行为的分析。你可能会发现，除自动刷新外，大部分用后喜欢上拉刷新，但下拉刷新的广告位更值钱（有问题存在就有工作要做了）。
auto_type：在新session，打开app到达首页会有一次自动刷新（即用户没有手动操作），可用于分析用户主动刷新的行为。


### 采集方式

采集元素目前主要分为四大类：页面采集（Page）[弹窗的弹出也可以归类为页面元素上报]、按钮采集（Button）、输入框采集（Input）、列表曝光采集（Expose）。

1. 页面采集（Page）
用户每打开新页面都会上报一次页面访问记录（重新打开同一页面也会再次上报）。该条记录上报的内容是前端预先设定（有上报需求来源于业务侧），通常由页面上报名称和其它通用上报字段组成。通用上报字段因为是共有字段，我们最后一起说。来看看页面上报名称的设计，我的心得是：千万！不要！让前端自己决定！ 如果你希望你的数据来源一团浆糊  Whatever

页面ID上报结构：A_B_C_D：用这种层级下划线连接的方式，定义上报ID，就很清晰。如：page_id = BUSA_acp_home

定义：A业务线下，页面上报类，首页 的页面上报。

2. 按钮采集（Button）
用户每点击一个按钮都会上报一个按钮点击记录。该条记录上报的内容是前端预先设定（有上报需求来源于业务侧），通常由页面上报名称和其它通用上报字段组成。

按钮ID上报结构：btn_id = BUSB_acb_{prod/other/outer}_Alist#1_Productid 我仍然在用的一种按钮上报方式，体验不错。

定义：B业务线下，按钮上报类，{商品类，功能类，对外导流类 三种按钮类型 选其一}，按钮嵌在A列表的第二个位置（智能推荐，千人千面，此处仅代表单个用户的情形），按钮的产品号。

3. 输入框采集（Input）
记录用户在文本框输入的任何信息和动作。包括你与意中人交流时时，反复斟酌句读，辞藻，踌躇犹豫的矛盾心理，在此处都能记录得明明白白。

输入框上报结构：1：我稀饭你很久噜，做我女朋友中不 /2：我稀饭你很久噜 /3：一起吃个饭吧 / 4：你在做什么？你到家了嘛

——直男聊天案例  定义：首先输入了1，删除部分输入后到2，增加输入到3，4等等。

连带你的初始输入，删除，撤回……曲折的心路历程还有总输入时间，都会被记录且细化到毫秒级。所以不要再质疑企业能获取你的生日/身份证号/密码等信息，数据安全真的全靠自觉（以及草票）。

4. 列表曝光采集（Expose）
简单讲就是给用户看到了哪些元素。因为智能匹配或着死规则匹配的普及。每个分类的客户都会被给到企业认为合适的行为路径（哪一类的用户被推荐哪一类的产品，跳转哪一个页面早已被商家安排的明明白白 ）。

列表曝光上报结构：按钮ID，所在列表，所在页面以及其它通用上报字段。

定义：页面下曝光了哪些列表，这些列表中又展示了哪些按钮元素，分别在第n个位置。

5. 能采集到的东西肯定不限于此（Other）
能采集到的东西肯定不限于此（Other），终端位置，APP版本，终端内其它APP。。。只有你想不到~


## 术语

一、页面统计

页面统计，可以统计应用内各个页面的访问次数（PV），访问设备数（UV）和访问时长，以及各页面之间的流向关系。

页面访问数：当前页面的被访问的次数，即浏览量PV。

> 举例：首页，访问次数，1000次；

页面访问人数：访问该页面的活跃用户数，即独立访问数UV。

> 举例：首页，访问人数，100次；

页面访问时长：用户在页面的停留时长，即首页受访时长的总和。

> 举例：首页，访问总时长，136秒；

页面流向分布：页面流向（走向）分布，可统计出，当前页面和下一个页面（有多个）的流向关系。

> 举例，在“商品详情”这个页面中，可以进入“购买”、“收藏”、“返回列表”、共3个页面，即在“商品详情”页，可能的流向分布为：
>
> |   流向页面   |  占比    |
> | ---- | ---- |
> |   购买   |  30%    |
> |   收藏   |    20%  |
> |    返回列表  |   30%   |
> |    离开  |   20%   |
> 
> 其中，用户在该“商品详情”页面，没有进入对应的3个页面，即视为“离开应用”。

二、自定义事件统计

自定义事件，即记录用户的操作行为（如点击行为），记录用户操作行为中的具体细节；一般来说，通常所说的埋点，指的就是自定义事件。

埋点可以是某个按钮，某个点击区域，某个提示，甚至可以用来统计一些特定的代码是否被执行。在APP中，需要在代码中定义一个事件行为。

2.1简单事件统计
简单事件统计，即记录事件的发生次数（可理解为PV）和事件发生人数（可理解为UV）。

以一个常见的登录页为例，其事件统计的结果为：

|  事件ID   |  事件名称    |  事件发生次数    | 事件发生人数    |
| ---- | ---- | ---- |
|   input_phone   |   输入手机号   |  1000    |100    |
|   get_code   |   获取验证码   | 300    | 30    |
|   input_code   |    输入验证码  |    200  |   20  |
|   get_ua   |  查看用户协议    |   300   |  30   |
|   check_ua   |  确认用户协议    |   300   |  30   |
|   click_login   |  点击登录    |   300   |  30   |

事件ID：EventID，该名称可遵循一定的命名规范进行自行定义命名，将该事件ID写入需要跟踪的位置中即可。

事件名称：事件ID的一个中文名称，为方便查看。事件名称只是事件ID在前端页面的一个显示名称。

事件发生次数：即该事件总共发生的次数；可以理解为，在每个事件中，都会有个事件ID计数器，每当该事件被触发时，事件数即加1；

事件发生人数：即该事件的发生独立用户数，根据用户唯一标识，对事件发生次数进行去重。

事件转化漏斗：即按照一定的事件顺序，依次统计各个事件之间的转化率，如我们可以对登录注册中的一些关键步骤进行事件漏斗分析，
如输入手机号码，获取验证码、输入验证码等，以登录过程为例，其漏斗可设置为：输入手机号码->获取验证码->输入验证码->点击登录按钮，即由4个事件组成的漏斗。

根据对应的事件数，即可计算出各个事件的转化率，如输入手机号码发生次数为5000次，获取验证码的次数为4000次，那么输入手机号码后点击获取验证码的转化率为4000/5000*100=80%。如下表所示：

|  步骤编号   |  事件名称    |  事件发生次数    | 上一步转化率    | 总转化率    |
| ---- | ---- | ---- |
|   1   |   输入手机号   |  5000    |-    |-    |
|   2   |   获取验证码   | 4000    | 80%    | 80%    |
|    3  |    输入验证码  |    3000  |   75%  |   60%  |
|   4   |  点击登录    |   2000   |  66.67%   |  40%   |

利用事件参数进行精确统计：为方便对相同类型的事件类型进行归类，在事件统计中，提供了事件标签（label）的方法；即相同类型的事件可以使用相同的事件ID和不同的事件label，通过事件ID+事件label的方式，指代一个特定的事件。

在进行事件统计时，为了为了统计一些特定的行为数据，如商品价格，商品类型等具体数据，提供了事件参数的方法，通过使用key-value的方式，记录该事件的详细记录。

事件ID、事件label、事件参数的关系，即事件label有一系列事件参数，同时一部分事件label可以归类为一个事件ID下。

举例，在一个购买行为中，运营人员想查看用户在整个购买流程的详细参数，那么可以通过以下的事件埋点方式进行埋点；

在这个购买行为中，

购买就是事件ID，

浏览商品详情，收藏该商品，加入购物车等，就是一个一个的事件label；

在浏览商品详情中，“商品类型：电子产品”，“商品价格：1-100元”……，等，就是一对一对的key-value值



最后，通过对商品价格的分析，可以统计得出，用户所选择的商品价格的分布情况。

## 编写埋点文档的注意事项

1.  埋点文档只可增加，不可修改和删除
埋点文档不同于产品经理的其他文档，像PRD文档一般都是只写本次迭代的内容，但埋点文档需要自始至终都在原有的基础上进行填写，且不能对原有的埋点进行修改或删除。

2. 事件必须独立
为了确保埋点的准确性，需要让不同的事件之间相互独立，例如APP页面中的返回事件，要统计该页面的蹦失率（Bounce Rate）就需要统计有多少人点了返回按钮，但是每个页面可能都有返回按钮，如果只把Lable写成“返回”则很有可能会与其他页面的返回相互混淆，造成数据结果不正确，这个问题我们已经通过给每个EventID和Label加上唯一编码解决了。

另外一个注意点之前也提到过，就是通用的页面事件需保持唯一的编号，而不是用多个编号去统计同一个事件，造成数据的分散。如果有一个通用的页面可以通过不同的入口进入，那么可以在这个页面的事件中加入一个From_page的属性，来记录是从哪个入口进入到这个通用页面中来的。

3. 数据字典不重复
在一个大型的团队中可能会有多个产品经理一起维护一份埋点文档，为了确保每个事件属性的含义保持一致，所以数据字典中的每一个key也都是唯一的，如果自己需要的key已经由其他人定义好了，则可以直接拿过来使用。如果要定义之前没有出现过的key，则只需要在数据字典中添加，然后同步给其他产品经理即可。

4. 注意平台限制
不同的埋点平台可能对于事件和属性有上限的限制，例如友盟平台一个APP只能记录500个事件，每个事件只能定义10个属性，而talkingdata的事件是可以无上限记录的，每个事件可以记录50个属性，所以大家在撰写埋点文档的时候，一定要注意自己选择的平台是否对于事件有限制规则，以免出现无法记录的情况出现。

5. 埋点测试
埋点代码编写完成后需要对埋点进行测试，这个过程一般是和测试同事一起进行，用来确保埋点的数据上报正确，该统计的属性也都添加成功了。


## 常见

访问到到商品列表页的转化率：访问用户数最好是访问了首页+访问了商品列表页+访问商品详情页的人数去重后的UV，因为也有人直接 从商品列表页或商品详情页进入产品。这样算才能更精准。
加购>下单的转化率可能大于100%，比如：今天加购的用户可能在后天下单。
加购是一个按钮不是页面要格式化为页面处理。


在页面流向分布，有2个常见问题：

问题一：分析出的页面流向分布中，仅有离开应用这一个指标有结果？

造成这种情况的原因，可能有以下两点：

用户在该页面全部选择了离开用户（这种概率相对很小）；
该页面的下一级页面，没有做埋点，导致所有的下一级页面都没有数据，其结果就是离开应用的占比为100%；

问题二：页面流向分布中，离开应用的占比非常高，达到了40%以上？

与问题一类似，如果没有为每个页面添加统计代码，会导致这些页面统计不到，那么跳转到这些未添加统计代码的页面，将会被视为离开应用。

```
备注：页面流向分布的计算方法

页面的统计数据中，会返回以下数据：当前页面名称，来源页面名称，当前页面访问次数；

举例2：参照举例1中的页面流向分布，假定的页面统计数字如下：

|  当前页面名称   |  来源页面名称    |  当前页面访问次数    |
| ---- | ---- | ---- |
|   商品详情   |   -   |  100    |
|   购买   |   商品详情   | 30    |
|   收藏   |    商品详情  |    20  |
|    返回列表  |  商品详情    |   30   |

则，商品详情流向购买页面的占比为：在购买页面中，来源为商品详情的次数与商品详情总次数的比值，即20/100*100%=20%；

依次类推，可以分别计算出商品详情流向收藏、商品详情流向返回列表的占比；

离开应用的占比，即为1-(30+20+30)/100*100%=20%。

```


## 系统设计

一个优秀的企业级埋点体系应该同时满足：

成本低，埋点从需求到开发上线，再到数据分析，各方的操作成本低。
效率高，埋点模型全面、复用性高，不需要每个埋点需求都走一遍埋点流程。
质量好，通过机制和上线化的工具保证埋点需求端到端的交付。


设计灵活、全面、复用性高的埋点模型，提升埋点设计的效率，降低埋点应用和管理的成本。
制定清晰可落地的端到端埋点采集规范，定义埋点工作流以及每个环节的输入输出，保证参与埋点的各方高质量的产品。
开发线上工具支持埋点的管理、研发、测试验收等工作，提升效率。

（1）数据层面

源数据层：数据源的采集、埋点（客户端访问日志、服务端业务数据库表、sdk等）
数据加工层：结合业务，对收集到的数据进行加工、清洗（join）等操作
数据仓库层：依赖结构化规范的数据表，建设和维护数据仓库
数据应用层：规划与设计数据指标体系（构建核心指标框架；产品、运营等指标建设）
数据访问层：结合平台及应用产品，支撑业务方数据需求（如：统计平台、数据可视化平台、资源调度平台、渠道后台、用户画像平台、abtest平台等）
（2）产品层面

明确产品形态及定位，熟知业务功能（数据异动跟踪分析、数据解读与答疑）
数据驱动产品发展规划（版本迭代、数据反馈推进）。


## 流程

step1：梳理产品需求

作为数据产品经理，在版本迭代阶段，主要是从数据的角度出发去思考业务需求和问题点。

在产品需求文档的梳理过程中，可以就之前版本发现的问题参与需求的收集与讨论。通过数据论证，提出相关的优化改进方案或建议，给出更加合理的产品规划和需求优先级。

step2：产品需求评审

产品需求文档一般包含：

文档说明（功能优先级、修改历史）
需求分析（需求背景、需求价值或、预期目标、数据参考）
结构流程（业务流程和产品框架）
原型交互（客户端逻辑、服务端逻辑）
数据埋点
业务产品经理主导当前版本的功能规划及需求输出。数据产品经理则主要是负责数据埋点部分，需要我们全程参与需求文档的评审，理解产品功能结构和开发实现逻辑。

ps：由于各公司逐步重视 “通过数据驱动业务决策”。数据相关工作，部分公司会将其单独拆解出来，作为数据产品经理或数据分析师的主要职责。

step3：分析产品逻辑

当产品需求文档完成最终评审，意味着当前版本需求不会再做大的改动。此时就需要开始分析产品逻辑，理解产品核心目标和当下主要的问题点。

除了需要弄明白产品承载了哪些重要的信息和功能，以及这些信息和功能的想要达到的需求目标。还要通过深入的分析，挖掘各业务方重点关注的数据指标是什么，确立产品的第一关键指标。（即分析是在什么样的场景下要解决什么业务问题，为了解决这个业务问题，要通过什么样的数据指标衡量），项目中不同的角色关注的问题不同，我们可以更好地给出他们最想看的数据。

产品（功能点击量、使用率、功能留存、核心路径转化、改版效果、用户行为等）
运营（用户新增、活跃、流失、付费转化、分享等）
渠道（渠道新增、落地页pv/uv、渠道转化、渠道留存率、ROI等）
step4：统计需求评审

统计需评阶段，主要是进行统计事件的设计和给出数据采集埋点方案。一般情况下，在做统计需求评审时，可以优先梳理产品功能结构图，将产品的功能模块及跳转流程梳理出来，想清楚上游入口和下游出口是什么。这样做的目的也是在进行更加合理的数据指标体系的设计，以及避免埋点的重复。

ps：由于项目迭代节奏较快，推行敏捷开发（“小步快跑模式”），有时统计需求评审会和产品需求评审同时进行，就需要和业务产品保持紧密的信息对接。

step5：跟进需求开发

当产品和统计需求评审完成后，接下来会进入需求研发阶段。在开发实现产品功能需求时需要我们高频沟通，这样做的目的是为了保证数据采集的质量及数据分析的准确性。

step6：功能验收核对

除了产品功能的核对，数据层面主要核对内容是：

数据上报节点或时机是否准确
数据采集的结果是否真实有效/重复上报
新增/修改的统计项是否会影响到其他功能的上报规则
step7：上线数据监测

发版后，随着版本覆盖率的提升数据会逐渐起势。一般情况下，需要密切监测上线前3d的数据情况，并在3d后给出一份初步的数据波动趋势分析文档，主要目的是：发现是否存在统计上报异常的数据指标，产品功能若出现较大问题，也要及时关注可能会影响到的统计点。根据问题紧急程度，采取发紧急修复包或其他方式解决。

step8：数据分析总结

上线后若不存在什么问题。即可输出当前新版本的数据分析报告，主要用于向项目组成员同步该版本的数据分析结论和迭代优化建议，建议在发版2周后再拉取数据指标进行分析总结。因为时间越短，覆盖率越低，数据量级小，就不太能够说明问题。


## 流程中的问题解决

1）需求沟通，业务同学要把需求传达给数据团队；我们都知道，沟通是一个时间黑洞，应最大程度地提升埋点需求的沟通效率，让业务人员清楚有埋点需求应该找谁对接、如何把需求描述得清楚。

2）埋点设计，重点在于埋点模型，好的埋点模型抽象能力强，能够更全面的覆盖用户行为，也有更好的复用性，设计起来也更加简单，可以极大的提升埋点工作流的效率；埋点模型设计得好还能提升后续数据计算的性能。另外，因为我们考虑的是企业级的埋点体系建设，需要统一的设计。

3）需求评审：很必要把埋点当作一条独立的研发流程来看待，设置专门的埋点需求评审，这么做的好处，一方面是让大家重视埋点研发；另一方面，因为参与埋点的团队比较多，可以在需求评审时把大家聚到一起，同步埋点方案、业务价值、研发计划等，协同各方各司其职。

4）开发测试：研发和测试按照评审通过的 DRD 进行开发测试；埋点的研发是一项琐碎的工作，并且随着埋点越来越多，埋点代码的管理任务很重，这也是很多研发不愿意埋点的原因；埋点的测试是一件比较困难的事件，很多测试人员之前没有接触过专项工作，需要提供一些线上的工具帮助研发和测试提升效率。

5）埋点应用：这个环节主要是要维护好埋点的元数据信息，知道埋点和业务是如何关联，方便 BI 同学加工出业务需要的指标。
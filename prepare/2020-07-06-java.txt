我们 Java 编程代码为`.java`后缀的源文件，经过__Java编译器__（`javac`）编译成`.class`后缀的二进制字节码文件，字节码文件必须被专用的__Java解释器__来解释执行，目的是将字节码文件翻译成具体硬件环境和操作系统平台下的机器代码，所以 Java 是一种在编译基础上进行解释运行的语言。

以上，Java程序不能直接运行在现有操作系统平台上，必须运行在称为Java虚拟机（Java Vatual Machine，JVM）的软件平台上。

因为JVM并不是真实的物理机，所以没有寄存器，所以指令集是使用`栈`来存储中间数据，用来保持Java虚拟机的指令集尽量紧凑，也会有利于某些虚拟机的动态编译器和即时编译器的代码优化。

client Compiler
server Compiler

jit 即时分析？C1、C2、C1+C2
逃逸分析：同步消除、标量替换、栈分配（=标量替换）

字节码文件，魔数CAFEBABE，常量

首先会被加载到内存，类加载器ClassLoader双亲委派，准备、连接和初始化过程（class content），存储在的方法区

加载 --- 连接（验证-准备-解析）--- 初始化

我们先从 JVM 说起

JVM分为五大模块，类装载器子系统、运行时数据区、执行引擎、本地方法接口和垃圾收集模块。

运行时数据区分为Java堆、方法区、虚拟机栈、本地方法栈、程序计数器，可能包含直接内存（NIO）。

虚拟机栈（1M），栈帧（Stack Frame），

栈帧（Stack Frame），局部变量表、操作数栈、动态连接、返回地址、帧数据区

操作数栈
invokespecial（init）
invokevisual（method）
iadd
iload
istore

动态绑定 运行期去方法表栈
静态绑定 private static final 方法

方法表以数组的形式记录了当前类及其所有超类的可见方法字节码在内存中的直接地址
1. 子类方法表中继承了父类的方法
2. 相同的方法(相同的方法签名：方法名和参数列表，即被覆盖的方法)在所有类的方法表中的索引相同（这个很重要）

Java内存模型（Java Memory Model，JMM）
变量加载工作内存过程
use   assign
load  store
read  write

堆，分配1/4物理内存
-Xms 堆大小（最小）1/64
-Xmx 堆大小（最大）1/4
-Xmn 新生代大小
-Xss 栈大小（每个线程大小）

GC，1/3新生代（8:1:1），2/3老年代

分配到老年代的可能性，对象大、达到gc次数（15）、内存担保

32位操作系统中，最大可使用内存是4G（2^32），ordinary object pointer 普通对象指针，oop为32位，对象引用占用4个字节，

64位操作系统中，oop为64位，对象引用占用8个字节，占用了更多堆空间，加快了GC发生，增加GC开销，同时CPU可缓存的oop变少，降低了缓存效率，因此JVM支持对象的指针压缩，64位系统Java对象至少2个slot，即16字节，总是8字节对齐，因此可以使用偏移量的方式来表示对象引用，8*(2^32)=32G，使用35位来记录对象指针，

零基压缩，分配给JVM的内存大小必须在4-32G之间，对象头信息16字节-》12字节，对象引用类型8字节-》4字节，对象数组类型24字节-》16字节，对于非堆的对象指针和局部变量、传参、返回值、NULL指针不压缩

markword 8
klasspointer 8 ---> 4
array[] 4
实例
对齐块

反编译`javap`，javap -c ExampleXxx.class 

硬件 = CPU + 内存 + 硬盘
软件 = 程序 = 数据结构 + 算法

引用计数，可达性分析（图论）

标记整理，标记复制，cms，g1

内存分析
jconsole
visualvm
jstat
jmap
MAT

线程分析
jstat
TDA

内核态 用户态 切换
用户态在内存寄存器放入数据
执行陷阱程序
切换到内核态 

> 从 class 编译角度看返回值相同的方法

> 大小堆

> double 类型精度问题

找进程 top 命令
栈线程 top -pid
top -H-p
转二进制
jstack -pid

动态链接 class.forName、classLoader

> 前缀树 trie树

泛型 PECS法则
泛型不是协变

-----------------------------------------------------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------------------------------------------------

Java 的集合Collection

Collection -》 AbstractList -》 List -》 ArrayList/LinkedList

ArrayList 扩容 n + 1/2n + 2 最大 Integer.MAX

Collection -》 AbstractSet -》 Set -》 HashSet/LinkedHashSet/TreeSet


Collection -》 AbstractMap -》 Map -》 HashMap/LinkedHashMap/TreeMap

LinkedHashMap --- 双向列表 --- LRU

红黑树、2-3树

2-3树
1. 2叉节点有且只有两个孩子，并只能有一个节点
2. 3叉节点必有三个孩子，并只能包含两个数据值（从左至右递增）
3. 插入节点不能将该节点插到一个空节点，新的节点只能通过分裂或融合产生
4. 当2-3树只有2节点时，其只能是一颗满二叉树（完美）

  2|4            2|4            2|4|6            4               
 / | \          / | \          / | | \          / \
1  3  5|7      1  3  6        1  3 5  7        2   6
                    / \                       / \ / \
                   5   7                     1  3 5  7

红黑树根节点黑色
任意一个节点到叶子节点经过的黑色节点数量一样
新插入节点为红色 
节点只有红黑两种
叶子节点都是null
红节点的子节点为黑色

父红左叔黑，左插左左旋，右插左右旋
父红右叔黑，左插右左旋，右插右右旋

快速失败、安全失败、default关键字


HashMap关键点
数组+链表
jdk7 头插法，设计者认为新插入的数据和快会被用到
modCount 



方法
哈希 hash 散列性，2的倍数，&运算，2^n - 1 = 1111111.......
增加 put 算哈希值，比较并替换、新增
查找 get 算哈希，比较并返回
大小 size

扩容关键点  jdk7 大于阈值并且当前桶元素有值，jdk8 只要大于阈值

jdk7 死锁场景

红黑树 介于 完全平衡二叉树 和 链表 之间

jdk8 的 hash 方法不注重散列性

树化时机 index >= 7 ，即第 9 个元素增加的时候

jdk8 是尾插法

jdk8 resize 的方法


二叉树旋转
leftR(node y) {
node x = y.right
node temp = x.left
y.right = temp
x.left  = y
x.color = y.color
y.color = red
return x
}

rightR(node a) {
node x = a.left
node temp = x.left
a.right = node.temp
node x.right = a
return x
}

-----------------------------------------------------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------------------------------------------------


MySQL

B+树

文件ibd --- 段segment --- 区1MB --- 页16K --- 行 2~n行

InnoDB 页 16k （操作系统 4k）
文件头
页头
最小ID
最大ID
页内容
页目录

页合并，删除更新时达到50%Threhold触发
页分裂

快照读、当前读

三层树，1170 * 1170 * 16 约千万数据

SX锁、Gap锁 = next-key Lock

死锁
innodb.locktime
wait-for graph

聚簇索引、非聚簇索引

MVCC 多版本控制 redo log、undo log

Compact 类型、 Dynamic类型

行
变长字段长度-null标志-数据-隐藏列（transactionId、rollbackpoint、xx_id）

行指针

工具
proxy层 性能差 4个请求 mycat dbproxy
应用层 性能好 sharding_job

数据库的垂直拆分、水平拆分

-----------------------------------------------------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------------------------------------------------
mybatis

mybatis ---mapper映射 ---代理模式
   |   \
线程池  拦截器

解析config --- configuration 对象
解析mapper --- 生成mapperproxy

mapperRegister
knownMapper key为 class ，value 为 proxyFactory

简单的jdbc
driver --- connection --- statement --- resultset --- close

mybatis
config --- createsqlsession --- exector --- mapperproxy --- statement + paramhandler --- interceptor --- resulthandler --- close

有意思的 metaclass

-----------------------------------------------------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------------------------------------------------
Spring

Bean生命周期
扫描 package scan
收集 bean-definabtion map

aop技术本质 动态代理
jdk 动态代理
cglib

ProxyPostBeanProcessor 代理Bean后置处理器

所谓注入，就是为成员变量赋值，起到减少耦合的作用
set注入、构造注入

IOC 对成员变量赋值的控制权 = Spring配置文件 + Spring工厂   解耦和

依赖注入 DI，一个类需要另一个类称为依赖，解耦和

为什么需要FactoryBean？为了创建复杂对象。


生命周期的三个阶段
创建 construct 构造方法
初始化 init() 注入 set
销毁 destory()


ConsumerServiceFactoryBean的id必须为consumerService ？ 

BeanPostProcessor 后置处理器

SpringBean创建过程
调用构造方法
BeanPostProcessor 的 postProcessBeforeInitialzation(Bean, BeanName)
InitialBean（afterProperties方法）
init-method 注释方法
BeanPostProcessor 的 postProcessAfterInitialzation(Bean, BeanName)


AOP
MethodBeforeAdvise


改变SpringBean类型的方式
1.@Bean注解
2.FactoryBean的getObeject方法
3.FactoryBeanPostPeocessor  registerBean


implement BeanDefinetionRegistry
@Override
registerBeanDefinations

Springboot 为什么可以用注释，servlet3.0
> SPI 了解一下
@AutoConfigurationPackage
@Import
ImportSelector

spring.factories
扫描
缓存到concurrentHashMap，BeanDefinition
遍历map
验证BeanDefinition单例，懒加载，抽象
得到类，BeanDefinition.getClass
类推断构造方法---> 反射实例化一个对象
暴露工厂
判断并属性注入
调用aware
调用生命周期方法
完成AOP并put map
销毁

实现controller方法的三种方式
@Controller
继承RequestHandler
实现Controller

resolveHanler

SPI协议读取文件MATE-INF/services/javax.servlet.ServletContainerInitializer
配置内容 org.springframework.web.SpringServletContainerInitializer
该类实现了SpringServletContainerInitializer接口
扫描注解@HandlersTypes(WebApplicationInitializer.class)
调用onStartup方法


-----------------------------------------------------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------------------------------------------------
dev-ops
镜像
容器
仓库

docker search
pull
run/start/stop
ps -a


-----------------------------------------------------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------------------------------------------------

Tomcat

Socket                         Listeners            Filter Chain  
--------》  Engine -----》 Host -----------》 Context ----------------》 Servlet
Request

责任链

nginx

servlet -- cgi

-----------------------------------------------------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------------------------------------------------

多线程 + 锁（线程安全）

Java 线程与原生操作系统有直接的映射关系
在Java线程准备好后
创建原生线程
原生线程初始化后，调用run()
Java线程结束，原生线程回收

> 内部类Sync了解一下

> Unsafe了解一下

> ThreadLocal 内存泄漏！所以用完后一定要remove

线程池（队列）
synchroniousQueue
linkedBlockQueue
delayQueue

继承Thread 或者 实现 runnable/callable

经典守护线程 GC垃圾回收

默认生成的线程为用户线程

主线程会在所有用户线程结束后结束

线程调度器
分配时间片
（线程优先级1-10）
Thread.MIN_PROORITY 1
Thread.MAX_PROORITY 10
Thread.NORMAL 5


interrupt()方法，sleep()会报错


       start            
新建--------------就绪----------运行------------销毁terminnated
                   ^    阻塞     <blocked/waiting/time waited（sleep）


join方法  A线程{ B线程.join() } 会先执行B，在继续执行A

题例：按顺序执行线程

               原子性 --|
                        |--- synchronized
            |--可见性 --|
voletile ---|            
 内存屏障    |--有序性   happen-before



synchronized 
对象监视器 Monitor


monitor.enter  --- 代码块 --- monitor.exit --- goto throw --- monitor.exit

每个Thread通过`对象头信息`判断object是否有锁

锁升级
安全点


ReentratLock()
Lock接口                  synchronized关键字
只能修饰代码块             修饰方法、代码块
需要手动unLock()           出现异常会自动释放锁
等待锁的线程可中断
可tryLock
读写锁


多线程通信
notify   notifyAll  wait
是object方法，对象的控制权

生产-消费者模型


线程池
资源消耗 下降
响应速度 上升
可管理性 上升

参数
coreThread
maxThread
BlockQueue
RejectPocily
Factory
timeOut

ThreadPool（Executor）
池-------------------队列--------------饱和策略
core=2 max=5         size=10           abortPolicy

先执行1、2
然后3-12进入队列
然后13、14、15执行
接下来的16及以后的执行异常

SynchriousQueue  同步队列，只生成1个
LinkedBlockQueue 无界    Integer.MAX ?
ArrayBlockQueue   有界 Integer.MAX ?

> BlockQueue有四把锁，notempty、notfull

4种饱和策略
abort discard  callerDo   Discardoldest


4种线程池
cached    keepLived（0-&）60秒 SynchronousQueue
fixed     keepLived（n-n）0豪秒 LinkedBlockQueue

Singled     keepLived（1-1）0毫秒 LinkedBlockQueue
调度     scheduled（n-&）0纳秒 延时、周期DelayQueue



java.util.concurrent  
线程池框架
Executor  顶级类
       |
ExecutorService  定义
       |
ThreadPoolExecutor  核心实现类
       |
scheduledThreadPoolExecutor 定时线程池实现


Executors  工具类


创建10000线程的对比，时间从3秒缩减到100毫秒（8线程）


核心线程默认不超时
Executor executor.allCoreThreadTimeOut(true)



shutdown/shutdownNow(有返回List)
shutdown阻止新任务提交
shutdownNow阻止新任务提交，并中断当前运行中的线程，同时移除wokerqueue并返回
> 技术细节，比如正在请求资源的时候中断怎么处理的


线程池原理
private final Hashset<Worker> workers;  存放工作线程的集合

Worker结构 extends AbstractQueuedSynchrouizer
		final Thread thread ： 线程
		Runnable firstTask ： 第一个任务

构造器
Worker(Runnable firstTask) {
	setState(-1)
	this.firstTask = firstTask
	this.thread = getThreadFactory().newThread(this)  --- 把worker自己传入
}

所以Thread执行了Worker的run方法
woker.run() --- work.runwork(this)
其中有while循环每次执行完，置为null
判断task或者getTask()不为null
> getTask()从任务队列取，这里有判断，如果有timeout，用poll()，否则用take()

所以线程池创建Worker的时机
execute
addWorker方法
		addWorker(command, coreBoolean)
> coreBoolean 标记是否是核心线程


CAPACITY
ctl是一个32位的数，前3位表示状态，后29位表示数量

即 111..............  RUNNING
   000..............  SHUTDOWN
   001..............  STOP
   010..............  TIDYING
   011..............  TERMINTED

线程池状态

RUNING ---shutdown--- SHUTDOWN ---队列空，线程池任务空--- TIDYING ---terminated--- TERMINTED
RUNING ---shutdownnow--- STOP ---线程池任务空--- TIDYING ---terminated--- TERMINTED

有意思的部分
c & CAPACITY = 任务数量
c & ~CAPACITY = 线程池状态


for(;;) 与 while(true) 理论相同，可能while在编译代码中判断值

-----------------------------------------------------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------------------------------------------------

IO

BIO
NIO + selector 同步非阻塞


limit position
position 开始的地方
limit 结束的地方

读模式 position 当时 limit = size
写模式 position = 0 limit = length

BIO
应用             内核                   网卡
accept() --->
              receiveFrom(Block) ---> Socket
read()   --->


用户空间         内核空间
          拷贝                准备
socket   <-------- socket   <--------



Non-Block-IO ，不是NIO
应用                           内核                   网卡
accept() ----------------->
         （仅仅是返回值不同） receiveFrom(nonBlock) ---> Socket
read()   ----------------->


用户空间                       内核空间
          拷贝                            准备
socket   <-------------------- socket   <--------

BIO 和 NBIO的不同之处在于select()有没有返回



IO多路复用（mutipart IO）
应用                                  内核                   网卡
IO多路复用器
select() -----------------------> 维护socket状态
   |                                epoll函数           ---> Socket
handler()--accept()
					----------->  receiveFrom()
         --register()


用户空间                               内核空间
          拷贝                                      准备
Data   <------------------------- socketData   <----------------

ServerSocketChannel.open()
Selector.open() 多路复用器
ServerSocketChannel.register(Selector)
selector.selectedKey

Reactor模型  零拷贝
设计：单线程、多线程、主从

> io流不同，close方法不同，bytestream可以不关闭
> 字符流和字节流真正区别
-----------------------------------------------------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------------------------------------------------
jsonarray 实现？

-----------------------------------------------------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------------------------------------------------


反射 + 代理

-----------------------------------------------------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------------------------------------------------

分布式事务

2PC（perpare-commit） 两阶段提交 
       | --- 获取资源
一阶段 |
       |---- 预提交

二阶段 |---- 提交/回退


JTA/XA事务  即mysql.innodb、mq事务  

CAP 理论 | BASE 原则 
C --- 一致性
A --- 可用性
P --- 分区容忍性
分布式系统仅可满足 AP / CP
BA --- 基本可用
S --- 软状态
E --- 最终一致
保持幂等


ATOMIKOS 框架

TCC：try-confirm-cancel  需要幂等

git项目 tcc-transaction-natsts

涉及技术
AOP、反射、持久化、序列化、定时任务、动态代理 


-----------------------------------------------------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------------------------------------------------


分布式锁

setNx
lua

互斥性`value = ThreadLocal.uuid`
锁超时`expire`
支持阻塞/非阻塞`while(true) { getKey(...) }`
可重入`++i`
高可用`续命机制`

（AP）reddison 阻塞lock() 非阻塞tryLock()

redLock 红锁
RLock注入RedLock 聚集结果 半数成功 需要都是独立的主节点

哈希槽


-----------------------------------------------------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------------------------------------------------
一致性哈希


-----------------------------------------------------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------------------------------------------------


dobbo                   springcloud
 
gateway网关             zuul
zookeeper（CP过半机制）  eureka（AP）
netty                   默认rest的http/可选thrift
nacos注册中心            
sentine熔断             hystrix熔断
                        fegion声明式服务调用
                        slenth链路跟踪
                        ribbon路由
                        config配置中心


三步配置euraka
1. 引入eurake server 依赖
2. @EnableEurakeServer注解
3. 配置文件

注册自己 eurake.client.register_with_eurake = false
获取数据 eurake.client.fetch_registetry = false
暴露地址 eurake.client.server_url_default_zone = xxx.xxx.xxx.xxx


自动配置的eurake服务端
@EnableEurakeServer
       |@Import
EurakeServerMaerkerConfig
       |@Bean
     Mark ---》 激活了 EurakeServerAutoConfiguartion（因为@Condition）
       |
  相关@Bean配置  ----》 接口、注册表
       |@Import配置类
EurakeServerInitialConfiguration
	   |start()方法
EurakeServerBootstrapcontentInitialized
       |上下文、初始化
服务回调replicate、剔除envice
巧妙地动态延时、60秒续约


15分钟内剔除超过15%开始保护机制，不再剔除


客户端两个定时任务
1. 拉取列表
2. 定时注册
首次全量更新，后续增量（有三级缓存）


-----------------------------------------------------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------------------------------------------------

netty

Reactor 模型

-----------------------------------------------------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------------------------------------------------

MQ


消息队列的使用过程大概如下：

（1）客户端连接到消息队列服务器，打开一个channel。
（2）客户端声明一个exchange，并设置相关属性。
（3）客户端声明一个queue，并设置相关属性。
（4）客户端使用routing key，在exchange和queue之间建立好绑定关系。
（5）客户端投递消息到exchange。

RabbitMQ




在Rabbit MQ中，无论是生产者发送消息还是消费者接受消息，都首先需要声明一个MessageQueue。这就存在一个问题，是生产者声明还是消费者声明呢？
首先需要明确：

a)消费者是无法订阅或者获取不存在的MessageQueue中信息。

b)消息被Exchange接受以后，如果没有匹配的Queue，则会被丢弃。

如果是消费者去声明Queue，就有可能会出现在声明Queue之前，生产者已发送的消息被丢弃的隐患。
如果应用能够通过消息重发的机制允许消息丢失，则使用此方案没有任何问题。
但是如果不能接受该方案，这就需要无论是生产者还是消费者，在发送或者接受消息前，都需要去尝试建立消息队列。
这里有一点可以明确，如果客户端尝试建立一个已经存在的消息队列，Rabbit MQ不会做任何事情，并返回客户端建立成功的。


队列以下属性:

a) Exclusive：排他队列，如果一个队列被声明为排他队列，该队列仅对首次声明它的连接可见，并在连接断开时自动删除。
这里需要注意三点：其一，排他队列是基于连接可见的，同一连接的不同信道是可以同时访问同一个连接创建的排他队列的。
其二，“首次”，如果一个连接已经声明了一个排他队列，其他连接是不允许建立同名的排他队列的，这个与普通队列不同。
其三，即使该队列是持久化的，一旦连接关闭或者客户端退出，该排他队列都会被自动删除的。
这种队列适用于只限于一个客户端发送读取消息的应用场景。

b)  Auto-delete:自动删除，如果该队列没有任何订阅的消费者的话，该队列会被自动删除。这种队列适用于临时队列。

c)  Durable:持久化

d)  其他选项，例如如果用户仅仅想查询某一个队列是否已存在，如果不存在，不想建立该队列，仍然可以调用queue.declare，
只不过需要将参数passive设为true，传给queue.declare，
如果该队列已存在，则会返回true；
如果不存在，则会返回Error，但是不会创建新的队列。

ExchangeType和Binding决定了消息的路由规则。所以生产者想要发送消息，首先必须要声明一个Exchange和该Exchange对应的Binding。
可以通过 ExchangeDeclare和BindingDeclare完成。
在Rabbit MQ中，声明一个Exchange需要三个参数：ExchangeName，ExchangeType和Durable。
有三种类型的ExchangeType：direct ，fanout和topic，不同的Exchange会表现出不同路由行为。

生产者在发送消息时，都需要指定一个RoutingKey，当Exchange在接到该RoutingKey以后，会通过ExchangeType判断：
如果是Direct类型，则会将消息中的RoutingKey与该Exchange关联的所有Binding中的BindingKey进行比较，如果相等，则发送到该Binding对应的Queue中。
如果是  Fanout  类型，则会将消息发送给所有与该  Exchange  定义过  Binding  的所有  Queues  中去，其实是一种广播行为。
如果是Topic类型，则会按照正则表达式，对RoutingKey与BindingKey进行匹配，如果匹配成功，则发送到对应的Queue中。

在RabbitMQ中消费者有2种方式获取队列中的消息:

a)  一种是通过basic.consume命令，订阅某一个队列中的消息,channel会自动在处理完上一条消息之后，接收下一条消息。
（同一个channel消息处理是串行的）。
除非关闭channel或者取消订阅，否则客户端将会一直接收队列的消息。

b)  另外一种方式是通过basic.get命令主动获取队列中的消息，
但是绝对不可以通过循环调用basic.get来代替basic.consume，这是因为basic.get RabbitMQ在实际执行的时候，
是首先consume某一个队列，然后检索第一条消息，然后再取消订阅。
如果是高吞吐率的消费者，最好还是建议使用basic.consume。

但是这种情况下，如果消费者1处理的消息比较繁重，而消费者2处理的消息比较轻松地话，实际上应该让消费者2多处理一些消息，在消费者代码添加中如下代码：
如果有多个消费者同时订阅同一个队列的话，RabbitMQ是采用循环的方式分发消息的，每一条消息只能被一个订阅者接收。
RabbitMQ可以在若干consumer中间实现轮流调度(Round-Robin).

channel.basicQos(1);//阻止rabbitmq将消息平均分配到每一个消费者，会优先的发给不忙的消费者，如果当前的消费者在忙的话，就将消息分配给下一个消费者

RabbitMQ提供了ACK某一个消息的命令，当然也提供了Reject某一个消息的命令。
当客户端发生错误，调用basic.reject命令拒绝某一个消息时，可以设置一个requeue的属性，
如果为true，则消息服务器会重传该消息给下一个订阅者；
如果为false，则会直接删除该消息。当然，也可以通过ack，让消息服务器直接删除该消息并且不会重传。

Rabbit MQ默认是不持久队列
通过设置Exchange和MessageQueue的durable属性为true，可以使得队列和Exchange持久化，
但是这还不能使得队列中的消息持久化，这需要生产者在发送消息的时候，将delivery mode设置为2，
只有这3个全部设置完成后，才能保证服务器重启不会对现有的队列造成影响。

 持久化的代价就是性能损失,磁盘IO远远慢于RAM(使用SSD会显著提高消息持久化的性能) , 持久化会大大降低RabbitMQ每秒可处理的消息.两者的性能差距可能在10倍以上.

事务，txSelect()-txCommit()-txRollback(),将客户端与消息服务器同步起来，背离了消息队列解耦的本质。

Consumer是直接创建TCP链接到RabbitMQ吗?Channel，无论是要发布消息还是要获取消息 ,
应用程序都需要通过TCP连接到RabbitMQ.
应用程序连接并通过权限认证之后就要创建Channel来执行AMQP命令.
Channel是建立在实际TCP连接之上通信管道,
这里之所以引入channel的概念而不是直接通过TCP链接直接发送AMQP命令,
是出于两方面的考虑:建立上成百上千的TCP链接,一方面浪费了TCP链接,
一方面很快会触及系统瓶颈.引入了Channel之后多个进程与RabbitMQ的通信可以在一条TCP链接上完成.



mq消息丢失

生产者
- 网络
- 代码错误，nack未处理
- 未绑定队列

`不建议使用事务，使用消息确认机制，单条确认（同步），批量确认（同步），异步确认（加监听器）
生产者通过调用channel.confirmSelect方法将信道设置为confirm模式，
一旦信道进入confirm模式，所有在该信道上面发布的消息都会被指派一个唯一的ID（从1开始），
一旦消息被投递到所有匹配的队列之后，
RabbitMQ就会发送一个确认（Basic.Ack）给生产者（包含消息的唯一deliveryTag和multiple参数），
这就使得生产者知晓消息已经正确到达了目的地了。

同步的确认，可能涉及到超时产生的重复发送，经常的丢数据导致反复重发，性能下降
异步的确认，可能涉及到发送前消息的存储和nack数据的处理


未绑定队列的情况设置参数mandatory，
当mandatory设置为false时，出现上述情形broker会直接将消息扔掉。
当mandatory标志位设置为true时，
如果exchange根据自身类型和消息routeKey无法找到一个符合条件的queue，
那么会调用basic.return方法将消息返回给生产者。
通过调用channel.addReturnListener来添加ReturnListener监听器实现，
只要发送的消息，没有路由到具体的队列，ReturnListener就会收到监听消息。


RabbitMQ提供了alternate-exchange，备份交换器，
它可以将未被路由的消息存储在另一个exchange队列中，再在需要的时候去处理这些消息。
通过webui管理后台设置，当新建一个exchange业务的时候，
可以给它设置Arguments，这个参数就是 alternate-exchange，
其实alternate-exchange就是一个普通的exchange，类型最好是fanout 方便管理
当发送消息到指定的exchange时候，对应key没有路由到queue，就会自动转移到alternate-exchange对应的queue，起码消息不会丢失。

如果备份交换器和mandatory参数一起使用，会导致mandatory参数无效（很好理解）
`


MQ服务
- 未支持持久化
- 单节点宕机
- 集群数据部分不可用（RabbitMQ的特殊集群架构，每个队列绑定在对应节点上，集群中的其他节点只存储元数据，类似索引，只会同步对应的数据）
- 镜像模式发生意外

`其实就是解决服务的高可用问题HA，镜像集群模式
镜像模式至少采用3节点：2个磁盘节点和1个内存节点来保证

策略：

同步至所有的，一般不这么做，性能会受到极大影响
同步最多N个机器
只同步至符合指定名称的nodes

说明举例：节点1（内存结点）、节点2（磁盘节点）存储所有数据，节点3（磁盘节点）仅存储元数据，保证了节点1宕机，节点2可用，但是都挂了，就服务不可用了

HA 镜像队列有一个很大的缺点就是： 系统的吞吐量会有所下降

所以采用镜像模式，要根据具体的业务规则定制话处理，没那么重要的业务，消息丢了也没关系的场景，又要求必须高的性能的时候，镜像也可以不用设置。



`

消费者
- 宕机
- 代码错误消费ack后未处理

`默认使用了自动ack，可以切换为手动ack，
这样消费者没处理完消息不会发送ack,
如果在消费者拿到消息，没来得及处理的情况下自己挂了，
此时MQ集群会自动感知到，它就会自觉的重发消息给其他的消费者服务实例。`
this.channel.basicConsume(queue, false, consumerTag, this);
第二个参数设置 false 代表不自动ack
public static void ack(MessageContext context) {
        long deliveryTag = context.getEnvelope().getDeliveryTag();
        try {
            context.getChannel().basicAck(deliveryTag, false);// 手动ACK
        } catch (IOException e) {
            throw new MqAckException("消息ack出错：连接异常或远端关闭", context, e);
        }
    }

 Confirm机制，无法进行回滚，就是一旦服务器崩溃，生产者无法得到Confirm信息,建议数据支持去重，或者消息幂等性。





 消息由两部分组成:  payload and  label. "payload"是实际要传输的数据,至于数据的格式RabbitMQ并不关心,"label"描述payload,包括exchange name 和可选的topic tag.消息一旦到了consumer那里就只有payload部分了,label部分并没有带过来.RabbitMQ并不告诉你消息是谁发出的.这好比你收到一封信但是信封上是空白的.当然想知道是谁发的还是有办法的,在消息内容中包含发送者的信息就可以了.



Kafaka

事务性MQ RocketMQ

Paxos 算法

-----------------------------------------------------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------------------------------------------------

Redis

结构 string 结构 {len、space、数组}

雪崩 大面积缓存Key正好全面消失：缓存时间随机值
击穿 持续请求，某个Key缓存某个时刻正好消失：重新加载数据时加锁；物理不过期
穿透 访问某个一定没有值的缓存Key：缓存空值；布隆过滤器

> 跳跃表

-----------------------------------------------------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------------------------------------------------

MongoDB

MongoDB Compass

无模式

BSON

数据库
 |
Collection
 |
Document

_id 做主键

偶数为稳定版本！

自建DB目录
1. 命令行 mongod -dbpath ....
2. 配置文件 mongod -f ...\conf\...

mongo --host = ... --path = 27017
showdbs

配置文件：
	日志输出
	数据库地址
	后台运行

mongodb只有浮点数，所以需要NumberInt(xx)输出

三个默认库 showdbs
admin 权限
config 分片相关
local 这个数据不会被复制，用来存本地数据

mongdb
╔══════╗
║ 内存 ║
╠══════╣
║ 磁盘 ║
╚══════╝

use xxx
会在内存中创建db，当db中有collection时到磁盘，则会在dbs中显示

db 显示当前库
db.dropDatabase() 删除库 {"ok",1}
db.createCollection("xxx") 创建集合
show collections 显示所有集合
db.xxx.drop() 或 db.collection.drop("xxx") 删除
db.xxx.insert(BSON) 
db.xxx.find()
db.xxx.insertMany()

mongodb 投影查询
try_catch 插入

更新 分为覆盖/局部
覆盖后会仅剩更新后的内容
db.xxx.update({"_id","xxx"},{BSON})
               查找条件       更新内部
局部，仅修改部分
db.xxx.update({"_id","xxx"},{$set:{BSON}})
mongo 仅仅修改第一条，多条需要添加参数
db.xxx.update({"_id","xxx"},{$set:{BSON},multi:true})

自增
db.xxx.update({"_id","xxx"},{$inc:{BSON}})

删除文档
db.xxx.remove({BSON})
删除的时候，符合条件都会删除

db.xxx.count()
db.xxx.find.limit(x)
db.xxx.find.ship(x).limit(x).sort()

支持正则 
比较 gt lt gte lte ne
db.xxx.far{userid:{$min{xxx}}}

条件查询，先写$and...

mongodb 副本集
主从与副本集的区别
副本集两种类型，三个角色，主/从/仲裁，所以至少三台服务

配置副本集名称
replication:
	replsetname:xxx

聚集函数 group
key
cond
reduce(curr, result)
initial
finalize

-----------------------------------------------------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------------------------------------------------


zooKeeper

2181 端口

统一命名服务、集群管理、分布式配置管理

是一个数据库（有文件系统特点）

强一致性
弱一致性
最终一致性

领导-选举机制
过半机制

预提交，收到ack，提交（2pc）

集群启动
leader挂掉
follower挂掉



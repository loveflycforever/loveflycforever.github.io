从意识上要重视数据采集工作。数据的事情归结起来就两点：数据采集和数据分析。

数据分析的基础就是数据源，数据源一般分为两部分：一部分叫用户行为数据，主要在APP的前后端埋点；另一部分，叫业务数据，一般存储在后台数据库。

## 数据分析结论
APP的产品经理，通过分析笔者这类用户的行为数据，得出了以下结论：

用户查看排行榜后，80%选择对排行第一的产品进行下单购买，15%选择购买排名第二的产品，其它5%没有发生购买。（行为数据分析）。
笔者在后台被打上了高级用户标签，这种用户人数占活跃用户数的30%，但贡献了60%的交易额，同时这个标签群体的退货率不到2%。（业务数据分析）。
84%的用户在商品列表页翻页时，最多翻到4页就选择跳出，而最多翻页的用户，剔除极端异常数据后，一般是翻到10页左右。通常搜索结果在10页以上且发生购买的情况下，前五页商品被下单的概率高达88%。（行为数据、业务数据结合分析）。


# 清晰的数据埋点

产品可能产生的用户行为数据纷繁复杂，清晰的目标能让项目团队避免迷失在数据的海洋中，从而耗费大量的时间和机会成本。

数据埋点的前提是，团队需要首先明确目前产品最亟待解决的问题是什么。

举个例子，比如电商产品，那么可能最首要的问题就是交易额，如何突破交易额，分解下去，可能就涉及到流量、转化率、客单价、回购率等等，提升这些数据指标就是当前产品的首要问题。
在整个产品的分析和改进过程中，需要持续的观察这些指标的变化。


在分析的一开始，并不建议采集太多的用户行为，在这一点上，倒是很像做产品里面的MVP（最小可化产品）思路，敏捷地不断迭代，不要一下子把全部用户行为都采集齐全。
因为如果产品经理在一开始就试图设计实施一套庞大、全面的方案，很容易陷入复杂而又细节的泥潭并导致失败，即便最终成功，也极可能会（因为初期的错误规划）导致很多时间浪费。
在一开始只记录和分析与“产品目标”最为相关的少量用户行为（如浏览、购买、下单），这样很快就能有成果产出。

# 数据采集

数据采集的问题归结为三类：

不知道怎么采，包括采集什么数据以及用什么技术手段采集；
埋点混乱，出现埋错、漏埋这样的问题；
数据团队和业务工程团队配合困难，往往产品升级的优先级大于数据采集的优先级。

## 如何采集数据

### 第三方

第一种直接使用友盟、百度统计这样的第三方统计工具，嵌入 App SDK 或 JS SDK，来直接查看统计数据。这种方式的好处是简单、免费，因此使用非常普及。

对于看一些网站访问量、活跃用户量这样的宏观数据需求，基本能够满足。对于现在一些涉及订单交易类型的产品，仅仅宏观的简单统计数据已经不能满足用户的需求了。

更加关注一些深度的关键指标分析，例如：用户渠道转化、新增、留存、多维度交叉分析等。这个时候才发现第三方统计工具很难满足对数据的需求，而出现这样的问题并不是因为工具的分析能力薄弱，而是因为这类工具对于数据采集的不完整。

通过这种方式 SDK 只能够采集到一些基本的用户行为数据，比如设备的基本信息，用户执行的基本操作等。但是服务端和数据库中的数据并没有采集，一些提交操作，比如提交订单对应的成本价格、折扣情况等信息也没有采集，这就导致后续的分析成了“巧妇难为无米之炊”。

通过客户端 SDK 采集数据还有一个问题就是经常觉得统计不准，和自己的业务数据库数据对不上，出现丢数据的情况。这是前端数据采集的先天缺陷，因为网络异常，或者统计口径不一致，都会导致数据对不上。

### 业务数据库
第二种是直接使用业务数据库做统计分析，一般的互联网产品，后端都有自己的业务数据库，里面存储了订单、用户注册信息等数据，基于这些数据，一些常用的统计分析都能够搞定。

这种方式天然的就能分析业务数据，并且是实时、准确的。

但不足之处有两点：

一是业务数据库在设计之初就是为了满足正常的业务运转，给机器读写访问的。为了提升性能，会进行一些分表等操作。
一个正常的业务都要有几十张甚至上百张数据表，这些表之间有复杂的依赖关系。这就导致业务分析人员很难理解表含义。
即使硬着头皮花了两三个月时间搞懂了，隔天工程师又告诉你因为性能问题拆表了，你就崩溃了。

另一个不足之处是业务数据表的设计是针对高并发低延迟的小操作，而数据分析常常是针对大数据进行批量操作的，这样就导致性能很差。

### 基于日志

第三种是通过日志进行统计分析，这种方式相较于第二种，完成了数据的解耦，使业务数据和统计分析数据相互分离。
然而，这种方式的问题是“目的不纯”。日志往往是工程师为了方便 Debug 顺便搞搞，这样的日志对于业务层面的分析，常常“缺斤少两”。
并且从打印日志到处理日志再到输出结果，整个过程很容易出错。

只能采集前端数据，后端服务器和数据库中的数据，依旧是无可奈何的。
并且，即便进行前端数据采集，也无法深入到更细粒度。比如提交订单操作，订单运费、成本价格之类的维度信息，都丢失掉了，只剩下“提交”这一个行为类型。


## 基本原则

数据采集的基本原则是全和细。
全就是把多种数据源都进行采集，而不只是客户端的用户数据。
细就是强调多维度，把事件发生的一系列维度信息，比如订单运费、成本价格等，尽量多的记录下来，方便后续交叉分析。


对数据采集工作负责，每次数据采集点的增加或变更，都要经过系统化的审核管理，不能顺便搞搞。

最后，我这里要推荐 Event 数据模型，针对用户行为数据，简化成一张宽表，将用户的操作归结为一系列的事件。


## 怎么做

很多产品经理会将“用户行为”简单的等同于应用的页面（界面）或点击操作，其实这完全是两件事情。

用户行为是更加具体的一个事件定义，比如说用户“提交订单”这么一个行为，就可以定义为一个事件了，但是如果用页面点击去定义它，则过于抽象不具体，不能让其他人很直观地感受到这个事件定义出来到底是干嘛的。


第一步把所有的用户访问分为N个会话（我们会话的间隔时间定义为20分钟，也就是访问一个页面后如果超过20分钟才访问下一个页面，那下一个页面就算另外一个会话）。

第二步找出用户首次访问包含这些入口的会话。

第三步把用户的访问路径打横，遍历用户的访问路径如果满足我们定义的路径，这条路径就会算一个UV。计算时商品列表页它是从搜索来的，还是从分类来的，还是直接从首页来的已经提前打好标识。


在这个时候可以从以下几个方面来考虑：

产品目标可以通过哪几个重要指标衡量？
和指标最相关的用户的“关键行为”是什么？
用户在做「关键行为」之前和之后，还有哪些行为值得关注和分析？

![Image text](http://image.woshipm.com/wp-files/2017/03/AQl6wjeFwGRT3IT9onez.png)

根据上面梳理的用户行为流程及事件，我们可以尝试着梳理一下埋点事件表，如下图所示：

![Image text](http://image.woshipm.com/wp-files/2017/03/61b6Ivzc0auD0fHZEIXJ.png)

数据分析不能单纯的靠一些基本事件来进行，还涉及的事件属性会比较多，所以产品经理也可以在事件埋点表中补充关于事件属性这么一项。
为事件增加属性，是一种更细致的、更精确的记录和刻画用户行为的方式。
比如，某个用户打开了一个吹风机的商品详情页，可以详细描述如下： 事件：查看商品详情-商品类目：家用电器 -价格区间：100-399 -商品名称： 飞科吹风机 某某某型号…

![Image text](http://image.woshipm.com/wp-files/2017/03/wo12nw9aK2kBgBwU6yp1.png)



根据产品流程设计指标
在前面做了一系列的功课之后，我们就开始要根据产品的功能流程或者页面结构，定义好分析的目的，剥离关键流程，提炼关键指标。

购物环节：宝贝详情页>加入购物车>订单确定>订单提交>支付>支付结果

在这个过程中，你可能需要采集到从详情页到购物车的转化，从详情页到订单确认的转化，订单从确认到支付成功之间的漏斗模型。

那么对应的可以为详情页UV、购物车添加事件、订单确认事件、订单提交事件、支付事件、支付成功反馈事件。

注册流程：进入注册>注册信息填写>获取验证>注册成功

对应的可能想要了解到注册流程的转化，那么可以主要采集注册按钮点击事件、提交信息事件、获取验证事件、注册成功事件，再加上能够统计到渠道包信息，那么也就可以分析出，不同渠道下的用户转化效果。




## 术语

一、页面统计

页面统计，可以统计应用内各个页面的访问次数（PV），访问设备数（UV）和访问时长，以及各页面之间的流向关系。

页面访问数：当前页面的被访问的次数，即浏览量PV。

> 举例：首页，访问次数，1000次；

页面访问人数：访问该页面的活跃用户数，即独立访问数UV。

> 举例：首页，访问人数，100次；

页面访问时长：用户在页面的停留时长，即首页受访时长的总和。

> 举例：首页，访问总时长，136秒；

页面流向分布：页面流向（走向）分布，可统计出，当前页面和下一个页面（有多个）的流向关系。

> 举例，在“商品详情”这个页面中，可以进入“购买”、“收藏”、“返回列表”、共3个页面，即在“商品详情”页，可能的流向分布为：
>
> |   流向页面   |  占比    |
> | ---- | ---- |
> |   购买   |  30%    |
> |   收藏   |    20%  |
> |    返回列表  |   30%   |
> |    离开  |   20%   |
> 
> 其中，用户在该“商品详情”页面，没有进入对应的3个页面，即视为“离开应用”。

二、自定义事件统计

自定义事件，即记录用户的操作行为（如点击行为），记录用户操作行为中的具体细节；一般来说，通常所说的埋点，指的就是自定义事件。

埋点可以是某个按钮，某个点击区域，某个提示，甚至可以用来统计一些特定的代码是否被执行。在APP中，需要在代码中定义一个事件行为。

2.1简单事件统计
简单事件统计，即记录事件的发生次数（可理解为PV）和事件发生人数（可理解为UV）。

以一个常见的登录页为例，其事件统计的结果为：

|  事件ID   |  事件名称    |  事件发生次数    | 事件发生人数    |
| ---- | ---- | ---- |
|   input_phone   |   输入手机号   |  1000    |100    |
|   get_code   |   获取验证码   | 300    | 30    |
|   input_code   |    输入验证码  |    200  |   20  |
|   get_ua   |  查看用户协议    |   300   |  30   |
|   check_ua   |  确认用户协议    |   300   |  30   |
|   click_login   |  点击登录    |   300   |  30   |

事件ID：EventID，该名称可遵循一定的命名规范进行自行定义命名，将该事件ID写入需要跟踪的位置中即可。

事件名称：事件ID的一个中文名称，为方便查看。事件名称只是事件ID在前端页面的一个显示名称。

事件发生次数：即该事件总共发生的次数；可以理解为，在每个事件中，都会有个事件ID计数器，每当该事件被触发时，事件数即加1；

事件发生人数：即该事件的发生独立用户数，根据用户唯一标识，对事件发生次数进行去重。

事件转化漏斗：即按照一定的事件顺序，依次统计各个事件之间的转化率，如我们可以对登录注册中的一些关键步骤进行事件漏斗分析，
如输入手机号码，获取验证码、输入验证码等，以登录过程为例，其漏斗可设置为：输入手机号码->获取验证码->输入验证码->点击登录按钮，即由4个事件组成的漏斗。

根据对应的事件数，即可计算出各个事件的转化率，如输入手机号码发生次数为5000次，获取验证码的次数为4000次，那么输入手机号码后点击获取验证码的转化率为4000/5000*100=80%。如下表所示：

|  步骤编号   |  事件名称    |  事件发生次数    | 上一步转化率    | 总转化率    |
| ---- | ---- | ---- |
|   1   |   输入手机号   |  5000    |-    |-    |
|   2   |   获取验证码   | 4000    | 80%    | 80%    |
|    3  |    输入验证码  |    3000  |   75%  |   60%  |
|   4   |  点击登录    |   2000   |  66.67%   |  40%   |

利用事件参数进行精确统计：为方便对相同类型的事件类型进行归类，在事件统计中，提供了事件标签（label）的方法；即相同类型的事件可以使用相同的事件ID和不同的事件label，通过事件ID+事件label的方式，指代一个特定的事件。

在进行事件统计时，为了为了统计一些特定的行为数据，如商品价格，商品类型等具体数据，提供了事件参数的方法，通过使用key-value的方式，记录该事件的详细记录。

事件ID、事件label、事件参数的关系，即事件label有一系列事件参数，同时一部分事件label可以归类为一个事件ID下。

举例，在一个购买行为中，运营人员想查看用户在整个购买流程的详细参数，那么可以通过以下的事件埋点方式进行埋点；

在这个购买行为中，

购买就是事件ID，

浏览商品详情，收藏该商品，加入购物车等，就是一个一个的事件label；

在浏览商品详情中，“商品类型：电子产品”，“商品价格：1-100元”……，等，就是一对一对的key-value值



最后，通过对商品价格的分析，可以统计得出，用户所选择的商品价格的分布情况。

## 编写埋点文档的注意事项

1.  埋点文档只可增加，不可修改和删除
埋点文档不同于产品经理的其他文档，像PRD文档一般都是只写本次迭代的内容，但埋点文档需要自始至终都在原有的基础上进行填写，且不能对原有的埋点进行修改或删除。

2. 事件必须独立
为了确保埋点的准确性，需要让不同的事件之间相互独立，例如APP页面中的返回事件，要统计该页面的蹦失率（Bounce Rate）就需要统计有多少人点了返回按钮，但是每个页面可能都有返回按钮，如果只把Lable写成“返回”则很有可能会与其他页面的返回相互混淆，造成数据结果不正确，这个问题我们已经通过给每个EventID和Label加上唯一编码解决了。

另外一个注意点之前也提到过，就是通用的页面事件需保持唯一的编号，而不是用多个编号去统计同一个事件，造成数据的分散。如果有一个通用的页面可以通过不同的入口进入，那么可以在这个页面的事件中加入一个From_page的属性，来记录是从哪个入口进入到这个通用页面中来的。

3. 数据字典不重复
在一个大型的团队中可能会有多个产品经理一起维护一份埋点文档，为了确保每个事件属性的含义保持一致，所以数据字典中的每一个key也都是唯一的，如果自己需要的key已经由其他人定义好了，则可以直接拿过来使用。如果要定义之前没有出现过的key，则只需要在数据字典中添加，然后同步给其他产品经理即可。

4. 注意平台限制
不同的埋点平台可能对于事件和属性有上限的限制，例如友盟平台一个APP只能记录500个事件，每个事件只能定义10个属性，而talkingdata的事件是可以无上限记录的，每个事件可以记录50个属性，所以大家在撰写埋点文档的时候，一定要注意自己选择的平台是否对于事件有限制规则，以免出现无法记录的情况出现。

5. 埋点测试
埋点代码编写完成后需要对埋点进行测试，这个过程一般是和测试同事一起进行，用来确保埋点的数据上报正确，该统计的属性也都添加成功了。


## 常见

访问到到商品列表页的转化率：访问用户数最好是访问了首页+访问了商品列表页+访问商品详情页的人数去重后的UV，因为也有人直接 从商品列表页或商品详情页进入产品。这样算才能更精准。
加购>下单的转化率可能大于100%，比如：今天加购的用户可能在后天下单。
加购是一个按钮不是页面要格式化为页面处理。


在页面流向分布，有2个常见问题：

问题一：分析出的页面流向分布中，仅有离开应用这一个指标有结果？

造成这种情况的原因，可能有以下两点：

用户在该页面全部选择了离开用户（这种概率相对很小）；
该页面的下一级页面，没有做埋点，导致所有的下一级页面都没有数据，其结果就是离开应用的占比为100%；

问题二：页面流向分布中，离开应用的占比非常高，达到了40%以上？

与问题一类似，如果没有为每个页面添加统计代码，会导致这些页面统计不到，那么跳转到这些未添加统计代码的页面，将会被视为离开应用。

```
备注：页面流向分布的计算方法

页面的统计数据中，会返回以下数据：当前页面名称，来源页面名称，当前页面访问次数；

举例2：参照举例1中的页面流向分布，假定的页面统计数字如下：

|  当前页面名称   |  来源页面名称    |  当前页面访问次数    |
| ---- | ---- | ---- |
|   商品详情   |   -   |  100    |
|   购买   |   商品详情   | 30    |
|   收藏   |    商品详情  |    20  |
|    返回列表  |  商品详情    |   30   |

则，商品详情流向购买页面的占比为：在购买页面中，来源为商品详情的次数与商品详情总次数的比值，即20/100*100%=20%；

依次类推，可以分别计算出商品详情流向收藏、商品详情流向返回列表的占比；

离开应用的占比，即为1-(30+20+30)/100*100%=20%。

```


## 系统设计

一个优秀的企业级埋点体系应该同时满足：

成本低，埋点从需求到开发上线，再到数据分析，各方的操作成本低。
效率高，埋点模型全面、复用性高，不需要每个埋点需求都走一遍埋点流程。
质量好，通过机制和上线化的工具保证埋点需求端到端的交付。


设计灵活、全面、复用性高的埋点模型，提升埋点设计的效率，降低埋点应用和管理的成本。
制定清晰可落地的端到端埋点采集规范，定义埋点工作流以及每个环节的输入输出，保证参与埋点的各方高质量的产品。
开发线上工具支持埋点的管理、研发、测试验收等工作，提升效率。

（1）数据层面

源数据层：数据源的采集、埋点（客户端访问日志、服务端业务数据库表、sdk等）
数据加工层：结合业务，对收集到的数据进行加工、清洗（join）等操作
数据仓库层：依赖结构化规范的数据表，建设和维护数据仓库
数据应用层：规划与设计数据指标体系（构建核心指标框架；产品、运营等指标建设）
数据访问层：结合平台及应用产品，支撑业务方数据需求（如：统计平台、数据可视化平台、资源调度平台、渠道后台、用户画像平台、abtest平台等）
（2）产品层面

明确产品形态及定位，熟知业务功能（数据异动跟踪分析、数据解读与答疑）
数据驱动产品发展规划（版本迭代、数据反馈推进）。


## 流程

step1：梳理产品需求

作为数据产品经理，在版本迭代阶段，主要是从数据的角度出发去思考业务需求和问题点。

在产品需求文档的梳理过程中，可以就之前版本发现的问题参与需求的收集与讨论。通过数据论证，提出相关的优化改进方案或建议，给出更加合理的产品规划和需求优先级。

step2：产品需求评审

产品需求文档一般包含：

文档说明（功能优先级、修改历史）
需求分析（需求背景、需求价值或、预期目标、数据参考）
结构流程（业务流程和产品框架）
原型交互（客户端逻辑、服务端逻辑）
数据埋点
业务产品经理主导当前版本的功能规划及需求输出。数据产品经理则主要是负责数据埋点部分，需要我们全程参与需求文档的评审，理解产品功能结构和开发实现逻辑。

ps：由于各公司逐步重视 “通过数据驱动业务决策”。数据相关工作，部分公司会将其单独拆解出来，作为数据产品经理或数据分析师的主要职责。

step3：分析产品逻辑

当产品需求文档完成最终评审，意味着当前版本需求不会再做大的改动。此时就需要开始分析产品逻辑，理解产品核心目标和当下主要的问题点。

除了需要弄明白产品承载了哪些重要的信息和功能，以及这些信息和功能的想要达到的需求目标。还要通过深入的分析，挖掘各业务方重点关注的数据指标是什么，确立产品的第一关键指标。（即分析是在什么样的场景下要解决什么业务问题，为了解决这个业务问题，要通过什么样的数据指标衡量），项目中不同的角色关注的问题不同，我们可以更好地给出他们最想看的数据。

产品（功能点击量、使用率、功能留存、核心路径转化、改版效果、用户行为等）
运营（用户新增、活跃、流失、付费转化、分享等）
渠道（渠道新增、落地页pv/uv、渠道转化、渠道留存率、ROI等）
step4：统计需求评审

统计需评阶段，主要是进行统计事件的设计和给出数据采集埋点方案。一般情况下，在做统计需求评审时，可以优先梳理产品功能结构图，将产品的功能模块及跳转流程梳理出来，想清楚上游入口和下游出口是什么。这样做的目的也是在进行更加合理的数据指标体系的设计，以及避免埋点的重复。

ps：由于项目迭代节奏较快，推行敏捷开发（“小步快跑模式”），有时统计需求评审会和产品需求评审同时进行，就需要和业务产品保持紧密的信息对接。

step5：跟进需求开发

当产品和统计需求评审完成后，接下来会进入需求研发阶段。在开发实现产品功能需求时需要我们高频沟通，这样做的目的是为了保证数据采集的质量及数据分析的准确性。

step6：功能验收核对

除了产品功能的核对，数据层面主要核对内容是：

数据上报节点或时机是否准确
数据采集的结果是否真实有效/重复上报
新增/修改的统计项是否会影响到其他功能的上报规则
step7：上线数据监测

发版后，随着版本覆盖率的提升数据会逐渐起势。一般情况下，需要密切监测上线前3d的数据情况，并在3d后给出一份初步的数据波动趋势分析文档，主要目的是：发现是否存在统计上报异常的数据指标，产品功能若出现较大问题，也要及时关注可能会影响到的统计点。根据问题紧急程度，采取发紧急修复包或其他方式解决。

step8：数据分析总结

上线后若不存在什么问题。即可输出当前新版本的数据分析报告，主要用于向项目组成员同步该版本的数据分析结论和迭代优化建议，建议在发版2周后再拉取数据指标进行分析总结。因为时间越短，覆盖率越低，数据量级小，就不太能够说明问题。


## 流程中的问题解决

1）需求沟通，业务同学要把需求传达给数据团队；我们都知道，沟通是一个时间黑洞，应最大程度地提升埋点需求的沟通效率，让业务人员清楚有埋点需求应该找谁对接、如何把需求描述得清楚。

2）埋点设计，重点在于埋点模型，好的埋点模型抽象能力强，能够更全面的覆盖用户行为，也有更好的复用性，设计起来也更加简单，可以极大的提升埋点工作流的效率；埋点模型设计得好还能提升后续数据计算的性能。另外，因为我们考虑的是企业级的埋点体系建设，需要统一的设计。

3）需求评审：很必要把埋点当作一条独立的研发流程来看待，设置专门的埋点需求评审，这么做的好处，一方面是让大家重视埋点研发；另一方面，因为参与埋点的团队比较多，可以在需求评审时把大家聚到一起，同步埋点方案、业务价值、研发计划等，协同各方各司其职。

4）开发测试：研发和测试按照评审通过的 DRD 进行开发测试；埋点的研发是一项琐碎的工作，并且随着埋点越来越多，埋点代码的管理任务很重，这也是很多研发不愿意埋点的原因；埋点的测试是一件比较困难的事件，很多测试人员之前没有接触过专项工作，需要提供一些线上的工具帮助研发和测试提升效率。

5）埋点应用：这个环节主要是要维护好埋点的元数据信息，知道埋点和业务是如何关联，方便 BI 同学加工出业务需要的指标。
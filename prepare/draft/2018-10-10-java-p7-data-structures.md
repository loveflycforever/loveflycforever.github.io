1. 链表与数组。
数组
在内存中，数组是一块连续的区域。
数组需要预留空间，在使用前要先申请占内存的大小，可能会浪费内存空间，并且不利于扩展。 
插入数据和删除数据效率低，随机读取效率很高。
链表
在内存中可以存在任何地方，不要求连续。
每一个数据都保存了下一个数据的内存地址，通过这个地址找到下一个数据。
增加数据和删除数据很容易。 
因为不具有随机访问性，查找数据时效率低。
不指定大小，扩展方便。

2. 队列和栈，出栈与入栈。
递归函数的实现就是借助于栈保存相关的数据。
操作系统中每个线程也会使用栈来保存函数调用涉及到的一些参数和其他变量等。

3. 链表的删除、插入、反向。

4. 字符串操作。
对于敏感信息,为何使用char[]要比String更好?
    String是不可变对象, 意思是一旦创建,那么整个对象就不可改变. 即使新手觉得String引用变了,实际上只是(指针)引用指向了另一个(新的)对象.
    而程序员可以明确地对字符数组进行修改,因此敏感信息(如密码)不容易在其他地方暴露(只要你用完后对char[]置0).
Java 7 中,substring()创建了一个新的char[] 数组,而不是共用.

5. Hash表的hash函数，冲突解决方法有哪些。
哈希法又称散列法、杂凑法以及关键字地址计算法等，相应的表称为哈希表。
哈希表（Hash table，也叫散列表），是根据key而直接进行访问的数据结构。也就是说，它通过把key映射到表中一个位置来访问记录，以加快查找的速度。这个映射函数叫做散列函数，存放记录的数组叫做散列表。
以数据中每个元素的关键字K为自变量，通过散列函数H（k）计算出函数值，以该函数值作为一块连续存储空间的的单元地址，将该元素存储到函数值对应的单元中。
当关键字集合很大时，关键字值不同的元素可能会映像到哈希表的同一地址上，即K1!=K2，但f(K1)=f(K2),这种现象称为hash冲突，实际中冲突是不可避免的，只能通过改进哈希函数的性能来减少冲突。
哈希函数的构造原则是：函数本身便于计算、计算出来的地址分布均匀（即对任意K，f(K)对应不同地址的概率相等）。
哈希函数的构造方法 ：
数字分析法：
可以从关键如果事先知道关键字集合，并且每个关键字的位数比哈希表的地址码位数多时，可以从关键字中选出分布较均匀的若干位，构成哈希地址。
平方取中法：
当无法确定关键字中哪几位分布较均匀时，可以先求出关键字的平方值，然后按需要取平方值的中间几位作为哈希地址。
分段叠加法：
这种方法是按哈希表地址位数将关键字分成位数相等的几部分（最后一部分可以较短），然后将这几部分相加，舍弃最高进位后的结果就是该关键字的哈希地址。具体方法有折叠法与移位法。
移位法是将分割后的每部分低位对齐相加，折叠法是从一端向另一端沿分割界来回折叠（奇数段为正序，偶数段为倒序），然后将各段相加。  
除留余数法：
假设哈希表长为m，p为小于等于m的最大素数，则哈希函数为 h（k）=k  %  p ，其中%为模p取余运算。
处理冲突的方法：
开放定址法(再散列法)：
当关键字key的哈希地址p=H（key）出现冲突时，以p为基础，产生另一个哈希地址p1，如果p1仍然冲突，再以p为基础，产生另一个哈希地址p2，…，                            直到找出一个不冲突的哈希地址pi ，将相应元素存入其中。
	线性探测再散列：冲突发生时，顺序查看表中下一单元，直到找出一个空单元或查遍全表。
	二次探测再散列：冲突发生时，在表的左右进行跳跃式探测，比较灵活。
	伪随机探测再散列：具体实现时，应建立一个伪随机数发生器，（如i=(i+p) % m），并给定一个随机数做起点。
再哈希法：
当哈希地址Hi=RH1（key）发生冲突时，再计算Hi=RH2（key）……，直到冲突不再产生。这种方法不易产生聚集，但增加了计算时间。
拉链法(HashMap的冲突处理方式):
将所有哈希地址为i的元素构成一个称为同义词链的单链表，并将单链表的头指针存在哈希表的第i个单元中，因而查找、插入和删除主要在同义词链中进行。链地址法适用于经常进行插入和删除的情况。
建立公共溢出区：
这种方法的基本思想是：将哈希表分为基本表和溢出表两部分，凡是和基本表发生冲突的元素，一律填入溢出表

6. 各种排序：冒泡、选择、插入、希尔、归并、快排、堆排、桶排、基数的原理、平均时间复杂度、最坏时间复杂度、空间复杂度、是否稳定。
冒泡排序
基本思想是:两两比较相邻记录的关键字,如果反序则交换
冒泡排序时间复杂度最好的情况为O(n),最坏的情况是O(n^2) 
改进思路1：设置标志位，明显如果有一趟没有发生交换（flag = false)，说明排序已经完成
改进思路2：记录一轮下来标记的最后位置，下次从头部遍历到这个位置就Ok
选择排序
通过n-i次关键字之间的比较,从n-i+1 个记录中选择关键字最小的记录,并和第i(1<=i<=n)个记录交换之
尽管与冒泡排序同为O(n^2),但简单选择排序的性能要略优于冒泡排序
直接插入排序
将一个记录插入到已经排好序的有序表中, 从而得到一个新的,记录数增1的有序表 
时间复杂度也为O(n^2), 比冒泡法和选择排序的性能要更好一些
希尔排序
先将整个待排元素序列分割成若干子序列（由相隔某个“增量”的元素组成的）分别进行直接插入排序，然后依次缩减增量再进行排序，待整个序列中的元素基本有序（增量足够小）时，再对全体元素进行一次直接插入排序（增量为1）。
其时间复杂度为O(n^3/2),要好于直接插入排序的O(n^2)
归并排序
假设初始序列含有n个记录,则可以看成n个有序的子序列,每个子序列的长度为1,然后两两归并,得到(不小于n/2的最小整数)个长度为2或1的有序子序列,再两两归并,...如此重复,直至得到一个长度为n的有序序列为止,这种排序方法称为2路归并排序。
 时间复杂度为O(nlogn),空间复杂度为O(n+logn),如果非递归实现归并,则避免了递归时深度为logn的栈空间 空间复杂度为O(n)
快速排序
通过一趟排序将要排序的数据分割成独立的两部分，其中一部分的所有数据都比另外一部分的所有数据都要小，然后再按此方法对这两部分数据分别进行快速排序，整个排序过程可以递归进行，以此达到整个数据变成有序序列。
时间复杂度为O(nlogn)
堆排序
堆是具有下列性质的完全二叉树:每个节点的值都大于或等于其左右孩子节点的值,称为大顶堆；
或者每个节点的值都小于或等于其左右孩子节点的值,称为小顶堆。
堆排序就是利用堆进行排序的方法.基本思想是:将待排序的序列构造成一个大顶堆.此时,整个序列的最大值就是堆顶 的根结点.将它移走(其实就是将其与堆数组的末尾元素交换, 此时末尾元素就是最大值),然后将剩余的n-1个序列重新构造成一个堆,这样就会得到n个元素的次大值.如此反复执行,便能得到一个有序序列了。 
时间复杂度为 O(nlogn),好于冒泡,简单选择,直接插入的O(n^2)
上述7种都是比较排序，下面3种都是非比较排序，理论上可以达到O(n)，比比较排序要快，但是这3种都是有其应用背景才能发挥作用的，否则适得其反。
桶排序
桶排序 (Bucket sort)或所谓的箱排序，是一个排序算法，工作的原理是将数组分到有限数量的桶子里。每个桶子再个别排序（有可能再使用别的排序算法或是以递归方式继续使用桶排序进行排序）
桶排序以下列程序进行：
    设置一个定量的数组当作空桶子。
    寻访串行，并且把项目一个一个放到对应的桶子去。（hash）
    对每个不是空的桶子进行排序。
    从不是空的桶子里把项目再放回原来的串行中。
基数排序
基数排序（英语：Radix sort）是一种非比较型整数排序算法，其原理是将整数按位数切割成不同的数字，然后按每个位数分别比较。由于整数也可以表达字符串（比如名字或日期）和特定格式的浮点数，所以基数排序也不是只能使用于整数。
它是这样实现的：将所有待比较数值（正整数）统一为同样的数位长度，数位较短的数前面补零。然后，从最低位开始，依次进行一次排序。这样从最低位排序一直到最高位排序完成以后, 数列就变成一个有序序列。
基数排序的方式可以采用LSD（Least significant digital）或MSD（Most significant digital），LSD的排序方式由键值的最右边开始，而MSD则相反，由键值的最左边开始。
计数排序
计数排序(Counting sort)是一种稳定的排序算法。计数排序使用一个额外的数组C，其中第i个元素是待排序数组A中值等于i的元素的个数。然后根据数组C来将A中的元素排到正确的位置。
算法的步骤如下：
    找出待排序的数组中最大和最小的元素
    统计数组中每个值为i的元素出现的次数，存入数组C的第i项
    对所有的计数累加（从C中的位置为1的元素开始，每一项和前一项相加）
    反向填充目标数组：将每个元素i放在新数组的第C(i)项，每放一个元素就将C(i)减去1
由于用来计数的数组C的长度取决于待排序数组中数据的范围（等于待排序数组的最大值与最小值的差加上1），这使得计数排序对于数据范围很大的数组，需要大量时间和内存。

7. 快排的partition函数与归并的Merge函数。

8. 对冒泡与快排的改进。

9. 二分查找，与变种二分查找。
// 这里必须是 <=
while (left <= right) {
    int mid = (left + right) / 2;
    if (array[mid] ? key) {
        //... right = mid - 1;
    }
    else {
        // ... left = mid + 1;
    }
}
return xxx;

10. 二叉树、B+树、AVL树、红黑树、哈夫曼树。
二叉搜索树           BST树
    若左子树不空，则左子树上所有结点的值均小于它的根节点的值；
    若右子树不空，则右子树上所有结点的值均大于它的根结点的值
    左、右子树也分别为二叉排序树
    没有键值相等的节点
如果一个完全二叉树的结点总数为768个，求叶子结点的个数。
由二叉树的性质知：n0=n2+1，将之带入768=n0+n1+n2中得：768=n1+2n2+1，因为完全二叉树度为1的结点个数要么为0，要么为1，那么就把n1=0或者1都代入公式中，很容易发现n1=1才符合条件。所以算出来n2=383，所以叶子结点个数n0=n2+1=384。
总结规律：如果一棵完全二叉树的结点总数为n，那么叶子结点等于n/2（当n为偶数时）或者(n+1)/2（当n为奇数时）
平衡二叉搜索树     AVL树
    AVL树是高度平衡的二叉树。它的特点是：AVL树中任何节点的两个子树的高度最大差别为1。 
红黑树                 RBT树
    红黑树是特殊的二叉查找树，意味着它满足二叉查找树的特征：任意一个节点所包含的键值，大于等于左孩子的键值，小于等于右孩子的键值。
    除了具备该特性之外，红黑树还包括许多额外的信息。
    红黑树的每个节点上都有存储位表示节点的颜色，颜色是红(Red)或黑(Black)。
    红黑树的特性:
    (1) 每个节点或者是黑色，或者是红色。
    (2) 根节点是黑色。
    (3) 每个叶子节点是黑色。 [注意：这里叶子节点，是指为空的叶子节点！]
    (4) 如果一个节点是红色的，则它的子节点必须是黑色的。
    (5) 从一个节点到该节点的子孙节点的所有路径上包含相同数目的黑节点。
哈夫曼树
    给定n个权值作为n个叶子结点，构造一棵二叉树，若树的带权路径长度达到最小，则这棵树被称为哈夫曼树。
B-树                    是一种平衡多路搜索树（并不是二叉的）
B+树                     B+树是B-树的变体，也是一种多路搜索树
B*树                     是B+树的变体，在B+树的非根和非叶子结点再增加指向兄弟的指针

11. 二叉树的前中后续遍历：递归与非递归写法，层序遍历算法。

12. 图的BFS与DFS算法，最小生成树prim算法与最短路径Dijkstra算法。










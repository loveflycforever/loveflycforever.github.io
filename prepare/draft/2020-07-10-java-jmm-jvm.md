---
layout: post
title:  "Java内存模型和内存结构"
subtitle: ""
tags: [Java, JMM, JVM]
comments: true
---
# 一、内存模型

# 1.1 硬件内存架构
计算机的中央处理器（CPU）数量可能会是两个或以上，而且每个CPU又会包含多个核心。因而，一个多线程应用的线程可能会分布在不同 CPU 的不同核心中并行运行。

当CPU需要从主存（RAM）读数据时，会先读取一部分主存数据到CPU缓存（CPU Cache），进而在读取CPU缓存中的数据到寄存器（Register）。当CPU需要写数据到主存时，同样会先flush寄存器到CPU缓存，然后再在某些节点把缓存数据flush到主存。

> CPU Cache，多级缓存，一般分为L1、L2、L3三级。

因为这些缓存的存在，提供了数据的访问性能，也减轻了数据总线上数据传输的压力。

内存模型可以理解为**在特定的操作协议下，对特定的内存或者高速缓存进行读写访问的过程抽象**。

比如，两个CPU同时去操作同一个内存地址，会在各自的Cache中缓存同一份数据的拷贝，如果其中一个CPU修改了这部分数据，这时就使得这两份缓存的数据不同，也就是另一个CPU Cache中的数据失效了。

**内存模型定义了一个充分必要条件，保证其它CPU的写入动作对该CPU是可见的，而且该CPU的写入动作对其它CPU也是可见的。**

不同架构下的物理机拥有不一样的内存模型。

# 顺序一致性内存模型（Sequential Consistency）

# 1.2.1 强内存模型（Strong  Memory Models）

有些处理器提供了强内存模型，所有CPU在任何时候都能看到内存中任意位置相同的值，这种完全是硬件提供的支持。

# 1.2.2 弱数据依赖排序（Weak With Data Dependency Ordering）

# 1.2.2 弱内存模型（Weak Memory Models）

其它处理器，提供了弱内存模型，需要执行一些特殊指令（memory barriers内存屏障），刷新CPU缓存的数据到内存中，保证这个写操作能够被其它CPU可见，或者将CPU缓存的数据设置为无效状态，保证其它CPU的写操作对本CPU可见。通常这些内存屏障的行为由底层实现，对于上层语言的程序员来说是透明的（不需要太关心具体的内存屏障如何实现）。

# 1.3 并发编程

在并发编程中，要处理的两个关键问题就是这两条标准的体现：线程之间如何通信以及线程之间如何同步。

# 1.3.1 线程之间如何通信

通信是指线程之间以何种机制来交换信息。

在命令式的编程中，线程之间的通信机制有两种：共享内存和消息传递。

# 1.3.1.1 共享内存模型

在 共享内存 并发的模型里，线程之间共享程序的公共状态，线程之间通过读/写内存中的公共状态来隐式进行通信。典型的共享内存通信方式就是通过共享对象进行通信。

# 1.3.1.2 消息传递模型

在 消息传递 的并发模型里，线程之间没有公共状态，线程之间必须通过明确的发送消息来显示进行通信，在 Java 中典型的消息传递方式就是`wait()`和`notify()`。

# 1.3.2 线程之间如何同步

同步是指程序用于控制不同线程之间操作发生相对顺序的机制。

# 1.3.2.1 共享内存模型

在 共享内存 并发模型里，同步是显示进行的，开发者必须显示指定某个方法或某段代码需要在线程之间互斥进行。

# 1.3.2.2 消息传递模型

在 消息传递 的并发模型里，由于消息的发送必须在消息的接受之前，因此同步是隐式进行的。


# 二、Java内存模型
Java 内存模型（JMM，Java Memory Model）本身是一种抽象的概念。

指的是 JDK 5 开始使用的新的内存模型，主要由` JSR-133: JavaTM Memory Model and Thread Specification（Java内存模型与线程规范）`描述。

可以理解为遵照多核硬件架构的设计，用 Java 实现了一套 JVM 层面的“缓存一致性”，这样就可以规避 CPU 硬件厂商的标准不一样带来的风险。

在C/C++语言中直接使用物理硬件和操作系统内存模型，导致不同平台下并发访问出错。

JMM 是一种符合内存模型规范的，屏蔽了各种硬件和操作系统的访问差异的，保证了 Java 程序在各种平台下对内存的访问都能保证效果一致的机制及规范。实现 Java 程序能够“一次编写，到处运行”。

# 2.1 Java 的并发采用的就是共享内存模型

JMM 定义了线程和主内存之间的抽象关系


    线程之间的共享变量存储在主内存（main memory）中，每个线程都有一个私有的本地内存（local memory），本地内存中存储了该线程以读/写共享变量的副本。

本地内存是 JMM 的一个抽象概念，并不真实存在。它涵盖了缓存，写缓冲区，寄存器以及其他的硬件和编译器优化（各种高级语言，包括Java，的多线程内存模型中，在线程栈内自己维护一份缓存是常见的优化措施）。

**线程对变量的操作都是在工作内存中完成，操作结束后再放回主内存**。

JMM 决定一个线程对共享变量的写入何时对另一个线程可见。

通信过程必须要经过主内存。JMM通过控制主内存与每个线程的本地内存之间的交互，提供内存可见性保证。

# 2.2 面临的问题

多线程通过共享内存进行通信时，存在**主内存和本地内存数据不一致、编译器对代码指令重排序、处理器对代码优化**等带来的问题，对应并发编程中的三个问题，可见性、有序性、原子性。

# 2.3 产生的原因

指令重排序（提高性能）、数据依赖性（不改变存在数据依赖关系的操作）、as-if-serial（单线程下的执行结果不变）、内存屏障（volatile）、happens-before

两个操作之间具有happens-before关系，并不意味前一个操作必须要在后一个操作之前执行！仅仅要求前一个操作的执行结果，对于后一个操作是可见的，且前一个操作按顺序排在后一个操作之前。

# 2.4 解决的方式

JMM 解决并发问题主要采用两种方式：**限制处理器优化和使用内存屏障**。

# 限制处理器优化

# 使用内存屏障

内存屏障，除了实现CPU之前的数据可见性之外，还有一个重要的职责，可以禁止指令的重排序。

这里说的重排序可以发生在好几个地方：编译器、运行时、JIT等，比如编译器会觉得把一个变量的写操作放在最后会更有效率，编译后，这个指令就在最后了（前提是只要不改变程序的语义，编译器、执行器就可以这样自由的随意优化），一旦编译器对某个变量的写操作进行优化（放到最后），那么在执行之前，另一个线程将不会看到这个执行结果。

当然了，写入动作可能被移到后面，那也有可能被挪到了前面，这样的“优化”有什么影响呢？这种情况下，其它线程可能会在程序实现“发生”之前，看到这个写入动作（这里怎么理解，指令已经执行了，但是在代码层面还没执行到）。通过内存屏障的功能，我们可以禁止一些不必要、或者会带来负面影响的重排序优化，在内存模型的范围内，实现更高的性能，同时保证程序的正确性。



硬件上的，被volatile修饰的变量在进行写操作时，会生成一个特殊的汇编指令，该指令会触发mesi协议，会存在一个总线嗅探机制的东西，简单来说就是这个cpu会不停检测总线中该变量的变化，如果该变量一旦变化了，由于这个嗅探机制，其它cpu会立马将该变量的cpu缓存数据清空掉，重新的去从主内存拿到这个数据。



# MESI协议的缓存状态机

MESI协议解决了CPU缓存层面的可见性问题。

M（修改, Modified）: 本地处理器已经修改缓存行, 即是脏行, 它的内容与内存中的内容不一样. 并且此cache只有本地一个拷贝（专有）。

E（专有, Exclusive）: 缓存行内容和内存中的一样, 而且其它处理器都没有这行数据。

S（共享, Shared）: 缓存行内容和内存中的一样, 有可能其它处理器也存在此缓存行的拷贝。

I（无效, Invalid）: 缓存行失效, 不能使用。

# 三、Java 内存结构

Java内存结构指的是Java虚拟机的`运行时数据区（Run-Time Data Areas）`的结构。

# 3.1 Java虚拟机栈（JVM Stack）

Java虚拟机栈，线程私有的，生命周期与线程相同。

会有两种异常`StackOverFlowError`和`OutOfMemoryError`。

- 当线程请求栈深度大于虚拟机所允许的深度就会抛出`StackOverFlowError`错误；
- 虚拟机栈动态扩展，当扩展无法申请到足够的内存空间时候，抛出`OutOfMemoryError`错误。

后进先出，栈帧是栈的元素

# 3.1.1 栈帧（Stack Frame）

一个线程的每个方法在执行的同时，都会创建一个栈帧（Stack Frame）。

每个方法从调用到运行结束的过程，就对应着一个栈帧在栈中压栈到出栈的过程。

当方法被调用时，栈帧在JVM栈中入栈，当方法执行完成时，栈帧出栈。

栈帧中存储了局部变量表、操作数栈、动态连接和方法出口等信息

一个栈帧需要分配多少内存，不会受到程序运行期变量数据的影响，而仅仅取决于具体的虚拟机实现。

# 3.1.2 局部变量表（Local Variables）

局部变量表中存储着方法的相关局部变量，包括各种基本数据类型，对象的引用，返回地址等。

局部变量表中最基本的存储单元是Slot（变量槽），每个变量槽都可以存储 32 位长度的内存空间。

基本类型数据以及引用和 returnAddress（返回地址）占用一个变量槽，long 和 double 需要两个。

在局部变量表中，只有`long`和`double`类型会占用2个**局部变量空间**（Slot，对于32位机器，一个Slot就是32个bit），其它都是1个Slot。

jvm规范中没有特定指定slot的大小，通常在32位操作系统中，slot占32位，此时long/double占两个slot。再64位操作系统中，slot占64位。所有数据类型都占1个slot。

JVM会为局部变量表中的每一个Slot都分配一个访问索引，通过这个索引即可成功访问到局部变量表中指定的局部变量值。

当一个实例方法被调用的时候，它的方法参数和方法体内部定义的局部变量将会按照顺序被复制到局部变量表中的每一个Slot上。

如果需要访问局部变量表中的一个64位的局部变量值时，只需要使用前一个索引即可。

如果当前帧是由构造方法或者实例方法创建的，那么该对象的引用this将会存放在index为0的Slot处，其余参数按照顺序排列。

局部变量表是在**编译时**就已经确定好的，方法运行所需要分配的空间在栈帧中是完全确定的，在方法的生命周期内都不会改变。

# 3.1.3 操作数栈（Operand Stacks）

后进先出，也称之为表达式栈，主要用于保存计算过程的中间结果，同时作为计算过程中变量临时的存储空间。

操作数栈是JVM执行引擎的一个工作区，当一个方法开始执行的时候，一个新的栈帧就会随之创建出来，这个时候方法的操作数栈是空的。

每一个操作数栈都会有一个明确的栈深度用于存储数值，其所需的最大深度在编译期间就已经定义好了，保存在方法的Code属性中，为max_stack的值。

32bit占用一个栈单位深度

64bit( long 和 double 类型)占用二个栈单位深度

# 3.1.4 动态连接（Dynamic Linking）

在类加载阶段中的解析阶段会将符号引用转为直接引用，这种转化也称为静态解析。另外的一部分将在运行时转化为直接引用，这部分称为动态链接。

每个栈帧都包含一个指向运行时常量池中该栈帧所属方法的引用，持有这个引用是为了支持方法调用过程中的动态链接。

每一个栈帧内部都包含一个指向运行时常量池中栈帧所属方法的引用。包含这个引用的目的就是为了支持当前方法的代码能够实现动态链接。比如：invokedynamic指令

在Java源文件中被编译到字节码文件中时，所有的变量和方法引用都作为符号引用（Symbolic Reference）保存在class文件的常量池中指向方法的符号引用来表示的，那么动态链接的作用就是为了将这些符号引用转换为调用方法的直接饮用。

# 3.1.5 返回地址（Return Address）

存放调用该方法的PC寄存器的值。

方法开始执行后，只有 2 种方式可以退出 ：方法返回指令，异常退出。

一个方法的结束要么正常执行结束，要么出现未处理异常，非正常退出。

无论哪种方式退出，在方法退出后都返回到该方法被调用的位置。方法正常退出时，调用者的PC寄存器的值作为返回地址，即调用该方法的下一条指令地址，而通过异常退出的，返回地址是要通过异常表来确定，栈帧中不会保存这部分信息。

区别在于，通过异常完成的出口不会给它上层调用者产生任何的返回值

# 3.1.5 帧数据区（Stack Data）

帧数据区的大小依赖于 JVM 的具体实现。

# 3.2 堆区（Heap）

在JVM所管理的内存中，堆区是最大的一块，堆区也是Java GC机制所管理的主要内存区域

《Java虚拟机规范》规定，堆可以处于物理上不连续的内存空间中，但在逻辑上它应该被视为连续的。

堆被所有线程共享区域，在虚拟机启动时创建，唯一目的存放对象实例。原则上讲，所有的对象都在堆区上分配内存（不过现代技术里，也不是这么绝对的，也有栈上直接分配的）。

所有的线程共享Java堆，在这里还可以划分线程私有的缓冲区( ThreadLocal Allocation Buffer， TLAB) 

> 什么是TLAB

  从内存模型而不是垃圾收集的角度，对Eden区继续进行划分，JVM为每个线程分配了一个私有缓存区域，它包含在Eden区内。

  多线程同时分配内存时，使用TLAB可以避免一系列的非线程安全问题，同时还能够提升内存分配的吞吐量，因此我们可以将这种内存分配方式称为快速分配策略。

堆区是gc的主要区域，通常情况下分为两个区块年轻代和年老代。更细一点年轻代又分为Eden区，放新创建对象，From survivor 和 To survivor 保存gc后幸存下的对象，默认情况下各自占比 8:1:1。

堆内存需要在逻辑上是连续的（在物理上不需要），在实现时，可以是固定大小的，也可以是可扩展的，目前主流的虚拟机都是可扩展的。

如果在执行垃圾回收之后，仍没有足够的内存分配，也不能再扩展，会抛出异常OutOfMemoryError:Java heap space。


堆是分配对象存储的唯一选择吗？
在Java虚拟机中，对象是在Java堆中分配内存的，这是一个普遍的常识。但是，有一种特殊情况，那就是如果经过逃逸分析（ Escape Analysis）后发现，一个对象并没有逃逸出方法的话，那么就可能被优化成栈上分配。这样就无需在堆上分配内存，也无须进行垃圾回收了。这也是最常见的堆外存储技术。
此外，基于 OpenJDK深度定制的 TaoBaoVM，其中创新的GCIH（GC invisible heap）技术实现off-heap，将生命周期较长的Java对象从heap中移至heap外，并且GC不能管理GCIH内部的Java对象，以此达到降低Gc的回收频率和提升GC的回收效率的目的。

"-Xms"用 于表示堆区的起始内存，等价于-XX: InitialHeapSize
"-Xmx" 则用于表示堆区的最大内存，等价于-XX :MaxHeapSize
一旦堆区中的内存大小超过“-Xmx"所指定的最大内存时，将会抛出OutOfMemoryError异常。
通常会将-Xms和-Xmx两个参数配置相同的值，其目的是为了能够在java垃圾回收机制清理完堆区后不需要重新分隔计算堆区的大小，从而提高性能。
默认情况下，初始内存大小:物理电脑内存大小 / 64，最大内存大小:物理电脑内存大小 / 4。

# 3.3 方法区（Method Area）/元空间区（MetaSpace）

《Java虚拟机规范》中明确说明：“尽管所有的方法区在逻辑上是属于堆的一部分，但一些简单的实现可能不会选择去进行垃圾收集或者进行压缩。” 但对于HotspotJVM而言，方法区还有一个别名叫做Non-Heap，目的就是要和堆分开。

所以方法区看作是一块独立于Java堆的内存空间。

《深入理解Java虚拟机》书中对方法区存储内容描述如下：它用于存储已被虚拟机加载的 类型信息、常量、静态变量、即时编译器编译后的代码缓存等。

被所有线程共享区域，用于存放已被虚拟机加载的类信息，final常量，静态变量，编译器即时编译的代码等数据。

被Java虚拟机描述为堆的一个逻辑部分。习惯是也叫它永久代（PermGen，permanent generation）

（由于之前的HotSpot Java虚拟机的实现方式中，将分代收集的思想扩展到了方法区，并将方法区设计成了永久代。不过，除HotSpot之外的多数虚拟机，并不将方法区当做永久代，HotSpot本身，也计划取消永久代。）

垃圾回收很少光顾这个区域，不过也是需要回收的，主要针对常量池内存回收，类型卸载。

常量池具有一定的动态性，里面可以存放编译期生成的常量；运行期间的常量也可以添加进入常量池中，比如string的intern()方法。

在方法区上定义了OutOfMemoryError:PermGen space异常，在内存不足时抛出。

方法区物理上存在于堆里，而且是在堆的持久代里面；但在逻辑上，方法区和堆是独立的。 一般说堆的持久代就是说方法区，因为一旦JVM把方法区（类信息，常量池，静态字段，方法）加载进内存以后，这些内存一般是不会被回收的了。

JDK 8 使用元空间 MetaSpace 代替方法区，元空间并不在JVM中，而是在本地内存中

方法区在JVM启动的时候被创建，并且它的实际的物理内存空间中和Java堆区一样都可以是不连续的。
方法区的大小，和堆空间一样，可以选择固定大小和可扩展。
方法区的大小决定了系统可以保存多少个类，如果系统定义了太多的类，导致方法区溢出，虚拟机就会抛出内存溢出错误：java.lang.OutOfMemoryError:PermGen space 或者 java.lang.OutOfMemoryError: Metaspace。
关闭JVM就会释放这个区域的内存。

JDK7及以前（永久代）：

通过"-XX:PermSize"设置永久代初始分配空间，默认值20.75M。
"-XX:MaxPermSize"来设置永久代最大可分配空间。32位机器默认是64M，64位机器默认是82M。
当JVM加载的类信息容量超过了这个值，则会报出OutOfMemoryError:Permgen Space。
JDK8（元空间）：

元数据区大小可以使用参数-XX:MetaspaceSize和-XX:MaxMetaspaceSize指定，替代上述原有的两个参数。
默认值依赖于平台。windows下，-XX:MetaspaceSize是21M，-XX:MaxMetaspaceSize的值是-1， 即没有限制。
与永久代不同，如果不指定大小，默认情况下，虚拟机会耗尽所有的可用系统内存。 如果元数据区发生溢出，虚拟机一样会拋出异常OutOfMemoryError： Metaspace。
-XX:MetaspaceSize： 设置初始的元空间大小。对于一个64位的服务器端JVM来说， 其默认的-XX:MetaspaceSize值为21MB.这就是初始的高水位线，一旦触及这个水位线，Full GC将会被触发并卸载没用的类（即这些类对应的类加载器不再存活），然后这个高水位线将会重置。新的高水位线的值取决于GC后释放了多少元空间。如果释放的空间不足，那么在不超过MaxMetaspaceSize时，适当提高该值。如果释放空间过多，则适当降低该值。
如果初始化的高水位线设置过低，上述高水位线调整情况会发生很多次。通过垃圾回收器的日志可以观察到Full GC多次调用。为了避免频繁地GC，建议将-XX:MetaspaceSize设置为一个相对较高的值。

# 3.4 程序计数器（Program Counter Register）

用于指示当前线程所执行的字节码执行到了第几行，可以理解为是当前线程的行号指示器。

通过改变计数器的值来确定下一条指令，比如循环，分支，跳转，异常处理，线程恢复等都是依赖计数器来完成。

为了线程切换能恢复到正确的位置，每条线程都需要一个独立的程序计数器，所以它是线程私有的。

程序计数器只是记录当前指令地址，因此是唯一一块Java虚拟机没有规定任何OutOfMemoryError的区块

# 3.5 直接内存（Direct Memory）

直接内存并不是JVM管理的内存，直接内存，就是JVM以外的机器内存，比如，你有4G的内存，JVM占用了1G，则其余的3G就是直接内存，

JDK中有一种基于通道（Channel）和缓冲区（Buffer）的内存分配方式，将由C语言实现的native函数库分配在直接内存中，用存储在JVM堆中的DirectByteBuffer来引用。

由于直接内存收到本机器内存的限制，所以也可能出现OutOfMemoryError的异常。

# 3.6 本地方法栈（Native Method Stack）

本地方法栈的作用，运行机制，异常类型等方面都与虚拟机栈相同

虚拟机栈是执行Java方法的，而本地方法栈是用来执行native方法的，

在虚拟机规范中对本地方法栈中方法使用的语言、使用方式与数据结构并没有强制规定，因此具体的虚拟机可以自由实现它。

在很多虚拟机中（如Sun的JDK默认的HotSpot虚拟机），会将本地方法栈与虚拟机栈放在一起使用。

本地方法栈也是线程私有的。

本地方法栈区域也会抛出StackOverflowError和OutOfMemoryError异常。

native方法，被native关键字修饰的方法叫做本地方法，本地方法和其它方法不一样，本地方法意味着和平台有关，因此使用了native的程序可移植性都不太高。

另外native方法在JVM中运行时数据区也和其它方法不一样，它有专门的本地方法栈。

native方法主要用于加载文件和动态链接库，由于Java语言无法访问操作系统底层信息（比如：底层硬件设备等），这时候就需要借助C语言来完成了。

被native修饰的方法可以被C语言重写。
```
1.Java程序中声明native修饰的方法，类似于abstract修饰的方法，只有方法签名，没有方法实现。编译该java文件，会产生一个.class文件。
2.使用javah编译上一步产生的class文件，会产生一个.h文件。
3.写一个.cpp文件实现上一步中.h文件中的方法。
4.将上一步的.cpp文件编译成动态链接库文件.dll。
5.最后就可以使用System或是Runtime中的loadLibrary()方法加载上一步的产生的动态连接库文件了。
```


当某个线程调用一个本地方法时，它就进入了一个全新的并且不再受虚拟机限制的世界。它和虚拟机拥有同样的权限。

本地方法可以通过本地方法接口来访问虚拟机内部的运行时数据区。2. 它甚至可以直接使用本地处理器中的寄存器。3. 直接从本地内存的堆中分配任意数量的内存。

# 四、垃圾回收

